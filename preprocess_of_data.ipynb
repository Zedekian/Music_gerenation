{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,glob\n",
    "import music21\n",
    "from music21 import *\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def note_to_int(note): # converts the note's letter to pitch value which is integer form.\n",
    "    \n",
    "    \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    if ('#-' in note):\n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[3]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('#' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('-' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    else:\n",
    "        first_letter = note[0]\n",
    "        base_val = note_base_name.index(first_letter)\n",
    "        octave = note[1]\n",
    "        value = base_val + 12*(int(octave)-(-1))\n",
    "        \n",
    "    return value\n",
    "\n",
    "min_value = 0.00\n",
    "lower_first = 0.00\n",
    "#lower_first = 0.1\n",
    "\n",
    "lower_second = 0.5\n",
    "#lower_second = 0.4\n",
    "upper_first = 0.5\n",
    "#upper_first = 0.6\n",
    "\n",
    "upper_second = 1.0\n",
    "#upper_second = 0.8\n",
    "max_value = 1.0\n",
    "\n",
    "def notes_to_matrix(notes, durations, offsets, min_value=min_value, lower_first=lower_first,\n",
    "                    lower_second=lower_second,\n",
    "                    upper_first=upper_first, upper_second=upper_second,\n",
    "                    max_value=max_value):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        last_offset = int(offsets[-1]) \n",
    "    except IndexError:\n",
    "        print ('Index Error')\n",
    "        return (None, None, None)\n",
    "    \n",
    "    total_offset_axis = last_offset * 4 + (8 * 4) \n",
    "    our_matrix = np.random.uniform(min_value, lower_first, (128, int(total_offset_axis))) \n",
    "    # creates matrix and fills with (-1, -0.3), this values will represent the rest.\n",
    "    \n",
    "    for (note, duration, offset) in zip(notes, durations, offsets):\n",
    "        how_many = int(float(duration)/0.25) # indicates time duration for single note.\n",
    "    \n",
    "        first_touch = np.random.uniform(upper_second, max_value, 1)\n",
    "        continuation = np.random.uniform(lower_second, upper_first, 1)\n",
    "        \n",
    "        if ('.' not in str(note)): # It is not chord. Single note.\n",
    "            our_matrix[note, int(offset * 4)] = first_touch\n",
    "            our_matrix[note, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "\n",
    "        else: # For chord\n",
    "            chord_notes_str = [note for note in note.split('.')] \n",
    "            chord_notes_float = list(map(int, chord_notes_str)) # Take notes in chord one by one\n",
    "\n",
    "            for chord_note_float in chord_notes_float:\n",
    "                our_matrix[chord_note_float, int(offset * 4)] = first_touch\n",
    "                our_matrix[chord_note_float, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "                \n",
    "    return our_matrix\n",
    "\n",
    "def check_float(duration): # This function fix the issue which comes from some note's duration. \n",
    "                        # For instance some note has duration like 14/3 or 7/3. \n",
    "    if ('/' in duration):\n",
    "        numerator = float(duration.split('/')[0])\n",
    "        denominator = float(duration.split('/')[1])\n",
    "        duration = str(float(numerator/denominator))\n",
    "    return duration\n",
    "\n",
    "def midi_to_matrix(filename, length=250): # Convert midi file to matrix for DL architecture.\n",
    "    \n",
    "    midi = converter.parse(filename)\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    try :\n",
    "        parts = music21.instrument.partitionByInstrument(midi)\n",
    "    except TypeError:\n",
    "        print ('Type error.')\n",
    "        return None\n",
    "    \n",
    "    instrument_names = []\n",
    "    \n",
    "    try:\n",
    "        for instrument in parts: # Learn names of instruments.\n",
    "            name = (str(instrument).split(' ')[-1])[:-1]\n",
    "            instrument_names.append(name)\n",
    "    \n",
    "    except TypeError:\n",
    "        print ('Type is not iterable.')\n",
    "        return None\n",
    "    \n",
    "    # Just take piano part. For the future works, we can use different instrument.\n",
    "    try:\n",
    "        piano_index = instrument_names.index('Piano')\n",
    "    except ValueError:\n",
    "        print ('%s have not any Piano part' %(filename))\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    notes_to_parse = parts.parts[piano_index].recurse()\n",
    "    \n",
    "    #duration_piano = float(check_float((str(notes_to_parse._getDuration()).split(' ')[-1])[:-1]))\n",
    "\n",
    "    durations = []\n",
    "    notes = []\n",
    "    offsets = []\n",
    "    \n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note): # If it is single note\n",
    "            notes.append(note_to_int(str(element.pitch))) # Append note's integer value to \"notes\" list.\n",
    "            duration = str(element.duration)[27:-1] \n",
    "            durations.append(check_float(duration)) \n",
    "            offsets.append(element.offset)\n",
    "\n",
    "        elif isinstance(element, chord.Chord): # If it is chord\n",
    "            notes.append('.'.join(str(note_to_int(str(n)))\n",
    "                                for n in element.pitches))\n",
    "            duration = str(element.duration)[27:-1]\n",
    "            durations.append(check_float(duration))\n",
    "            offsets.append(element.offset)\n",
    "\n",
    "    \n",
    "    \n",
    "    our_matrix = notes_to_matrix(notes, durations, offsets)\n",
    "    \n",
    "    try:\n",
    "        freq, time = our_matrix.shape\n",
    "    except AttributeError:\n",
    "        print (\"'tuple' object has no attribute 'shape'\")\n",
    "        return None\n",
    "            \n",
    "    if (time >= length):\n",
    "        return (our_matrix[:,:length]) # We have to set all individual note matrix to same shape for Generative DL.\n",
    "    else:\n",
    "        print ('%s have not enough duration' %(filename))\n",
    "\n",
    "def int_to_note(integer):\n",
    "    # Convert pitch value to the note which is a letter form. \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    octave_detector = (integer // 12) \n",
    "    base_name_detector = (integer % 12) \n",
    "    note = note_base_name[base_name_detector] + str((int(octave_detector))-1)\n",
    "    if ('-' in note):\n",
    "        note = note_base_name[base_name_detector] + str(0)\n",
    "        return note\n",
    "    return note\n",
    "\n",
    "\n",
    "lower_bound = (lower_first + lower_second) / 2\n",
    "upper_bound = (upper_first + upper_second) / 2\n",
    "\n",
    "def converter_func(arr,first_touch = 1.0, continuation = 0.0, lower_bound = lower_bound, upper_bound = upper_bound):\n",
    "    \n",
    "    np.place(arr, arr < lower_bound, -1.0)\n",
    "    np.place(arr, (lower_bound <= arr) & (arr < upper_bound), 0.0)\n",
    "    np.place(arr, arr >= upper_bound, 1.0)\n",
    "    return arr\n",
    "\n",
    "def how_many_repetitive_func(array, from_where=0, continuation=0.0):\n",
    "    new_array = array[from_where:]\n",
    "    count_repetitive = 1 \n",
    "    for i in new_array:\n",
    "        if (i != continuation):\n",
    "            return (count_repetitive)\n",
    "        else:\n",
    "            count_repetitive += 1\n",
    "    return (count_repetitive)\n",
    "\n",
    "def matrix_to_midi(matrix, random=0):\n",
    "    first_touch = 1.0\n",
    "    continuation = 0.0\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    output_notes = []\n",
    "    offset = 0\n",
    "        \n",
    "    # Delete rows until the row which include 'first_touch'\n",
    "    how_many_in_start_zeros = 0\n",
    "    for x_axis_num in range(x_axis):\n",
    "        one_time_interval = matrix[:,x_axis_num] # Values in a column.\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_start_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    how_many_in_end_zeros = 0\n",
    "    for x_axis_num in range(x_axis-1,0,-1):\n",
    "        one_time_interval = matrix[:,x_axis_num] # values in a column\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_end_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    print ('How many rows for non-start note at beginning:', how_many_in_start_zeros)\n",
    "    print ('How many rows for non-start note at end:', how_many_in_end_zeros)\n",
    "\n",
    "    matrix = matrix[:,how_many_in_start_zeros:]\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    print (y_axis, x_axis)\n",
    "\n",
    "    for y_axis_num in range(y_axis):\n",
    "        one_freq_interval = matrix[y_axis_num,:] # Values in a row.\n",
    "        \n",
    "        one_freq_interval_norm = converter_func(one_freq_interval)\n",
    "        \n",
    "        i = 0        \n",
    "        offset = 0\n",
    "        \n",
    "        if (random):\n",
    "        \n",
    "            while (i < len(one_freq_interval)):\n",
    "                how_many_repetitive = 0\n",
    "                temp_i = i\n",
    "                if (one_freq_interval_norm[i] == first_touch):\n",
    "                    how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                    i += how_many_repetitive \n",
    "\n",
    "                if (how_many_repetitive > 0):\n",
    "                    random_num = np.random.randint(3,6)\n",
    "                    new_note = note.Note(int_to_note(y_axis_num),duration=duration.Duration(0.25*random_num*how_many_repetitive))\n",
    "                    new_note.offset = 0.25*temp_i*2\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    output_notes.append(new_note)\n",
    "                else:\n",
    "                    i += 1\n",
    "        \n",
    "        \n",
    "        else:\n",
    "        \n",
    "            while (i < len(one_freq_interval)):\n",
    "                how_many_repetitive = 0\n",
    "                temp_i = i\n",
    "                if (one_freq_interval_norm[i] == first_touch):\n",
    "                    how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                    i += how_many_repetitive \n",
    "\n",
    "                if (how_many_repetitive > 0):\n",
    "                    new_note = note.Note(int_to_note(y_axis_num),duration=duration.Duration(0.25*how_many_repetitive))\n",
    "                    new_note.offset = 0.25*temp_i\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    output_notes.append(new_note)\n",
    "                else:\n",
    "                    i += 1\n",
    "        \n",
    "    return output_notes\n",
    "\n",
    "\n",
    "\n",
    "def visualize_adjacency_matrix(adjacency_matrix):\n",
    "    fig, ax = plt.subplots()\n",
    "    cmap = plt.get_cmap(\"binary\")\n",
    "    n = len(adjacency_matrix)\n",
    "    \n",
    "    im = ax.imshow(adjacency_matrix, cmap=cmap)\n",
    "    \n",
    "    ax.set_xticks(np.arange(n))\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_xticklabels(np.arange(1, n + 1))\n",
    "    ax.set_yticklabels(np.arange(1, n + 1))\n",
    "    \n",
    "    # 設定 x, y 軸的 tick\n",
    "    x_major_ticks = ticker.MultipleLocator(4)\n",
    "    y_major_ticks = ticker.MultipleLocator(4)\n",
    "    ax.xaxis.set_major_locator(x_major_ticks)\n",
    "    ax.yaxis.set_major_locator(y_major_ticks)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def extract_bars_from_midi(midi_file):\n",
    "    midi_score = converter.parse(midi_file)\n",
    "    bars = []\n",
    "    for part in midi_score.parts:\n",
    "        bar_stream = part.makeMeasures()\n",
    "        for bar in bar_stream:\n",
    "            bars.append(bar)\n",
    "    return bars\n",
    "\n",
    "def extract_bars_from_musicxml(xml_file):\n",
    "    score = converter.parse(xml_file)\n",
    "    bars = []\n",
    "    for part in score.parts:\n",
    "        measures = part.getElementsByClass('Measure')\n",
    "        for measure in measures:\n",
    "            bars.append(measure)\n",
    "    return bars\n",
    "\n",
    "def get_pitch_interval(note1, note2):\n",
    "    if not isinstance(note1, note.Note) or not isinstance(note2, note.Note):\n",
    "        return None\n",
    "    else:\n",
    "        return interval.notesToChromatic(note1, note2).semitones\n",
    "\n",
    "def count_notes_in_bar(bar):\n",
    "    notes_list = bar.flat.notes\n",
    "    notes_counter = Counter()\n",
    "    total_duration = 0.0\n",
    "    \n",
    "    for item in notes_list:\n",
    "        if item.isNote:\n",
    "            notes_counter[item.nameWithOctave] += item.duration.quarterLength\n",
    "            total_duration += item.duration.quarterLength\n",
    "        elif item.isChord:\n",
    "            chord_duration = max([n.duration.quarterLength for n in item.notes])\n",
    "            for n in item.notes:\n",
    "                notes_counter[n.nameWithOctave] += chord_duration\n",
    "            total_duration += chord_duration\n",
    "                \n",
    "    return notes_counter, total_duration\n",
    "\n",
    "def are_bars_similar(bar1, bar2, threshold=0.9):\n",
    "    bar1_notes, bar1_duration = count_notes_in_bar(bar1)\n",
    "    bar2_notes, bar2_duration = count_notes_in_bar(bar2)\n",
    "\n",
    "    shared_keys = set(bar1_notes.keys()) & set(bar2_notes.keys())\n",
    "    total_shared_notes = sum([min(bar1_notes[key], bar2_notes[key]) for key in shared_keys])\n",
    "\n",
    "    total_duration = bar1_duration + bar2_duration\n",
    "    \n",
    "    if total_duration != 0:\n",
    "        similarity = (total_shared_notes * 2) / total_duration\n",
    "    else:\n",
    "        similarity = 0\n",
    "    return similarity >= threshold\n",
    "\n",
    "\n",
    "def create_adjacency_matrix(bars ,status):\n",
    "    num_bars = len(bars)\n",
    "    adjacency_matrix = np.zeros((num_bars, num_bars))\n",
    "\n",
    "    if status == 'repeat':\n",
    "\n",
    "        for i in range(num_bars):\n",
    "            for j in range(i + 1, num_bars):\n",
    "                if are_bars_similar(bars[i], bars[j]):\n",
    "                    adjacency_matrix[i, j] = 1\n",
    "                    adjacency_matrix[j, i] = 1\n",
    "\n",
    "    elif status == 'rhythm':\n",
    "        for i in range(num_bars):\n",
    "            for j in range(i + 1, num_bars):\n",
    "                bar1_notes = [n for n in bars[i].flat.notesAndRests if not isinstance(n, note.Rest)]\n",
    "                bar2_notes = [n for n in bars[j].flat.notesAndRests if not isinstance(n, note.Rest)]\n",
    "\n",
    "                distances = []\n",
    "                for n1 in bar1_notes:\n",
    "                    for n2 in bar2_notes:\n",
    "                        dist = get_pitch_interval(n1, n2)\n",
    "                        if dist is not None:\n",
    "                            distances.append(dist)\n",
    "                if len(distances) > 0:\n",
    "                    mean_distance = sum(distances) / len(distances)\n",
    "\n",
    "                    # Add a weight for the rhythmic relationship between the bars\n",
    "                    # The weight is the absolute value of the difference between the durations of the first note/rest in each bar\n",
    "                    bar1_duration = 0.0\n",
    "                    for n in bar1_notes:\n",
    "                        if n.duration.quarterLength > 0.0:\n",
    "                            bar1_duration = n.duration.quarterLength\n",
    "                            break\n",
    "\n",
    "                    bar2_duration = 0.0\n",
    "                    for n in bar2_notes:\n",
    "                        if n.duration.quarterLength > 0.0:\n",
    "                            bar2_duration = n.duration.quarterLength\n",
    "                            break\n",
    "                    '''\n",
    "                    rhythm_weight = abs(bar1_duration - bar2_duration)\n",
    "                    if (mean_distance - rhythm_weight) > 0:\n",
    "                        adjacency_matrix[i][j] = 1\n",
    "                        adjacency_matrix[j][i] = 1\n",
    "                    '''\n",
    "                    rhythm_weight = abs(bar1_duration - bar2_duration)\n",
    "                    '''\n",
    "                    adjacency_matrix[i][j] = mean_distance + rhythm_weight\n",
    "                    adjacency_matrix[j][i] = mean_distance + rhythm_weight\n",
    "                    '''\n",
    "                    # Only show 1 or 0\n",
    "                    adjacency_matrix[i][j] = 1 if mean_distance + rhythm_weight > 0 else 0\n",
    "                    adjacency_matrix[j][i] = 1 if mean_distance + rhythm_weight > 0 else 0\n",
    "                    \n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "def merge_metrix(adj_1,adj_2):\n",
    "    \n",
    "    n = len(adj_1)\n",
    "    \n",
    "    merged_matrix = [[0] * (2 * n) for _ in range(2 * n)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            merged_matrix[i][j] = adj_1[i][j]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            merged_matrix[n+i][n+j] = adj_2[i][j]\n",
    "    \n",
    "    return merged_matrix\n",
    "\n",
    "def music_to_adjacency_metrix(file, bars_len):\n",
    "\n",
    "    midi_file = file\n",
    "    #midi_file = '../bestekar/midi_files/classic/schumann/schum_abegg_format0.mid'\n",
    "\n",
    "    # Extract first 32 bars\n",
    "    if midi_file.endswith(\".mxl\"):\n",
    "        bars = extract_bars_from_musicxml(midi_file)[:bars_len]   #for xml files\n",
    "\n",
    "    elif midi_file.endswith(\".mid\"):\n",
    "        bars = extract_bars_from_midi(midi_file)[:bars_len]  #for midi files\n",
    "\n",
    "    bars_repeat = create_adjacency_matrix(bars, 'repeat')\n",
    "    bars_rhythm = create_adjacency_matrix(bars, 'rhythm')\n",
    "\n",
    "    merge_adj = merge_metrix(bars_repeat, bars_rhythm)\n",
    "\n",
    "    return merge_adj\n",
    "\n",
    "def music_to_feature(midi_file):\n",
    "\n",
    "    features_list = []\n",
    "    features_list = midi_to_matrix(midi_file, length=500)\n",
    "    f = np.array(features_list)\n",
    "   \n",
    "    return f\n",
    "\n",
    "def merge_list_and_tensor(list_data, tensor_data):\n",
    "    \n",
    "    list_data = torch.tensor(list_data, dtype=torch.float32)\n",
    "    #merge_list = torch.cat([list_data, tensor_data], dim=0)\n",
    "    merge_list = torch.zeros((list_data.size(0), list_data.size(1)* 2))\n",
    "    merge_list[:, :list_data.size(1)] = list_data\n",
    "    merge_list[:tensor_data.size(0), list_data.size(1):] = tensor_data\n",
    "    #merge_list = merge_list[:, :300]#take first 300\n",
    "\n",
    "    return merge_list\n",
    "\n",
    "def reshape_feature(data ,dim):\n",
    "    \n",
    "    data_var = np.var(data, axis=1)\n",
    "    top_indices = np.argsort(data_var)[::-1][:dim]\n",
    "\n",
    "    selected_feature = data[top_indices,:]\n",
    "    selected_feature = torch.tensor(selected_feature,dtype=torch.float32)\n",
    "\n",
    "    return selected_feature\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, adjacency_matrix, feature_matrix):\n",
    "        # 计算传播规则\n",
    "        support = torch.matmul(adjacency_matrix, feature_matrix)\n",
    "        output = self.linear(support)\n",
    "        output = self.dropout(output)\n",
    "        output = F.relu(output)\n",
    "        return output\n",
    "\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.layer1 = GCNLayer(input_dim, hidden_dim, dropout_rate)\n",
    "        self.layer2 = GCNLayer(hidden_dim, output_dim, dropout_rate)\n",
    "\n",
    "    def forward(self, adjacency_matrix, feature_matrix):\n",
    "        hidden = self.layer1(adjacency_matrix, feature_matrix)\n",
    "        output = self.layer2(adjacency_matrix, hidden)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def GCN_trainning(merge_adj, f):\n",
    "\n",
    "    adjacency_matrix = torch.tensor(merge_adj, dtype=torch.float32)\n",
    "    #feature_matrix = torch.tensor(f , dtype=torch.float32)\n",
    "    feature_matrix = f.clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "    input_dim = feature_matrix.shape[1]\n",
    "    hidden_dim = 16\n",
    "    output_dim = 500    #250\n",
    "    dropout_rate = 0.22\n",
    "\n",
    "    \n",
    "    \n",
    "    model = GCNModel(input_dim, hidden_dim, output_dim, dropout_rate)\n",
    "\n",
    "    output = model(adjacency_matrix, feature_matrix)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    output = model(adjacency_matrix, feature_matrix)\n",
    "    #print(output.size())\n",
    "    #print(model)\n",
    "    for epoch in range(300):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with noisy input and original adjacency matrix.\n",
    "        output = model(adjacency_matrix, feature_matrix)\n",
    "\n",
    "        # Compute reconstruction loss between the output and the original input.\n",
    "        loss = F.mse_loss(output, feature_matrix)\n",
    "\n",
    "        # Backward pass and optimization step.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        '''\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 100, loss.item()))\n",
    "        '''\n",
    "    return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zed/zed_code/music_gerenation\n",
      "['../bestekar/midi_files/classic/schumann/scn16_6_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_12.mid', '../bestekar/midi_files/classic/schumann/scn16_5_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_4_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_9_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_8_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_12_format0.mid', '../bestekar/midi_files/classic/schumann/scn16_3_format0.mid', '../bestekar/midi_files/classic/schumann/scn68_12_format0.mid', '../bestekar/midi_files/classic/schumann/scn16_7_format0.mid', '../bestekar/midi_files/classic/schumann/scn68_10_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_7.mid', '../bestekar/midi_files/classic/schumann/scn15_11.mid', '../bestekar/midi_files/classic/schumann/scn15_1.mid', '../bestekar/midi_files/classic/schumann/scn15_10_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_2_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_3.mid', '../bestekar/midi_files/classic/schumann/schum_abegg_format0.mid', '../bestekar/midi_files/classic/schumann/scn16_1_format0.mid', '../bestekar/midi_files/classic/schumann/scn16_2_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_2.mid', '../bestekar/midi_files/classic/schumann/scn16_3.mid', '../bestekar/midi_files/classic/schumann/scn15_3_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_4.mid', '../bestekar/midi_files/classic/schumann/scn15_9.mid', '../bestekar/midi_files/classic/schumann/scn68_12.mid', '../bestekar/midi_files/classic/schumann/scn15_8.mid', '../bestekar/midi_files/classic/schumann/scn16_7.mid', '../bestekar/midi_files/classic/schumann/scn16_8.mid', '../bestekar/midi_files/classic/schumann/scn16_1.mid', '../bestekar/midi_files/classic/schumann/scn15_5.mid', '../bestekar/midi_files/classic/schumann/scn16_5.mid', '../bestekar/midi_files/classic/schumann/scn16_6.mid', '../bestekar/midi_files/classic/schumann/scn16_4.mid', '../bestekar/midi_files/classic/schumann/scn15_1_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_13_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_7_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_13.mid', '../bestekar/midi_files/classic/schumann/scn68_10.mid', '../bestekar/midi_files/classic/schumann/scn15_5_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_10.mid', '../bestekar/midi_files/classic/schumann/scn15_6.mid', '../bestekar/midi_files/classic/schumann/scn16_4_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_6_format0.mid', '../bestekar/midi_files/classic/schumann/scn15_11_format0.mid', '../bestekar/midi_files/classic/schumann/scn16_8_format0.mid']\n",
      "../bestekar/midi_files/classic/schumann/scn16_6_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_12.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_12.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn16_5_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_4_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_4_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_9_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_8_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_8_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_12_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_12_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn16_3_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn68_12_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_7_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn68_10_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn68_10_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_7.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_11.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_1.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_1.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_10_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_10_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_2_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_3.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_3.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/schum_abegg_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_1_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_2_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_2.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_3.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_3_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_3_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_4.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_4.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_9.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn68_12.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_8.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_8.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn16_7.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_8.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_1.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_5.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_5.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn16_5.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_6.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_4.mid\n",
      "../bestekar/midi_files/classic/schumann/scn16_4.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_1_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_1_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_13_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_13_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_7_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn15_13.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_13.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn68_10.mid\n",
      "../bestekar/midi_files/classic/schumann/scn68_10.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_5_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_5_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_10.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_10.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_6.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_6.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn16_4_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn16_4_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_6_format0.mid\n",
      "../bestekar/midi_files/classic/schumann/scn15_6_format0.mid have not enough duration\n",
      "../bestekar/midi_files/classic/schumann/scn15_11_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "../bestekar/midi_files/classic/schumann/scn16_8_format0.mid\n",
      "torch.Size([128, 1000])\n",
      "[Midis_array_raw shape :] (24, 128, 1000)\n"
     ]
    }
   ],
   "source": [
    "database_npy = 'midis_array_schumann.npy'\n",
    "\n",
    "print (os.getcwd())\n",
    "\n",
    "root_dir = ('../bestekar/midi_files/')\n",
    "all_midi_paths = glob.glob(os.path.join(root_dir, 'classic/schumann/*mid'))\n",
    "\n",
    "\n",
    "print (all_midi_paths)\n",
    "matrix_of_all_midis = []\n",
    "\n",
    "BARS_LENGTH = 32 # Set the bars length\n",
    "\n",
    "# All midi have to be in same shape. \n",
    "\n",
    "for single_midi_path in all_midi_paths:\n",
    "\n",
    "    print (single_midi_path)\n",
    "    matrix_of_single_midi = midi_to_matrix(single_midi_path, length=500)\n",
    "\n",
    "    if (len(music_to_adjacency_metrix(single_midi_path, BARS_LENGTH))) < (BARS_LENGTH * 2): #Skip the mismatch music\n",
    "        continue\n",
    "    \n",
    "    if (matrix_of_single_midi is not None):\n",
    "\n",
    "        merge_adj = music_to_adjacency_metrix(single_midi_path, BARS_LENGTH)\n",
    "        f = music_to_feature(single_midi_path)\n",
    "        f = reshape_feature(f, BARS_LENGTH * 2)  #降維後的張量大小\n",
    "        GCN_feature = GCN_trainning(merge_adj, f)\n",
    "        matrix_of_single_midi = merge_list_and_tensor(matrix_of_single_midi, GCN_feature)\n",
    "        matrix_of_all_midis.append(matrix_of_single_midi)\n",
    "        print (matrix_of_single_midi.shape)    \n",
    "\n",
    "to_cpu_tensor = [item.clone().detach() for item in matrix_of_all_midis]\n",
    "cpu_tensor = [item.cpu().detach().numpy() for item in to_cpu_tensor]\n",
    "gpu_tensor = torch.tensor(cpu_tensor).cuda()\n",
    "cpu_tensor = gpu_tensor.cpu()\n",
    "midis_array = np.asarray(cpu_tensor)\n",
    "np.save(database_npy, midis_array)\n",
    "    \n",
    "midis_array_raw = midis_array\n",
    "print (\"[Midis_array_raw shape :]\",(midis_array_raw.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
