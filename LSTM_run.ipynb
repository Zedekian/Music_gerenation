{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,glob\n",
    "import music21\n",
    "from music21 import *\n",
    "from pathlib import Path\n",
    "environment.set('midiPath', '/usr/bin/musescore3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is GPU active?\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!cat /proc/meminfo \\nfrom tensorflow.python.client import device_lib\\ndevice_lib.list_local_devices()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see information about RAM.\n",
    "'''\n",
    "!cat /proc/meminfo \n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_to_int(note): # converts the note's letter to pitch value which is integer form.\n",
    "    # source: https://musescore.org/en/plugin-development/note-pitch-values\n",
    "    # idea: https://github.com/bspaans/python-mingus/blob/master/mingus/core/notes.py\n",
    "    \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    if ('#-' in note):\n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[3]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('#' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('-' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    else:\n",
    "        first_letter = note[0]\n",
    "        base_val = note_base_name.index(first_letter)\n",
    "        octave = note[1]\n",
    "        value = base_val + 12*(int(octave)-(-1))\n",
    "        \n",
    "    return value\n",
    "\n",
    "min_value = 0.00\n",
    "#lower_first = 0.00\n",
    "lower_first = 0.1\n",
    "\n",
    "#lower_second = 0.5\n",
    "lower_second = 0.4\n",
    "#upper_first = 0.5\n",
    "upper_first = 0.6\n",
    "\n",
    "#upper_second = 1.0\n",
    "upper_second = 0.8\n",
    "max_value = 1.0\n",
    "\n",
    "def notes_to_matrix(notes, durations, offsets, min_value=min_value, lower_first=lower_first,\n",
    "                    lower_second=lower_second,\n",
    "                    upper_first=upper_first, upper_second=upper_second,\n",
    "                    max_value=max_value):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        last_offset = int(offsets[-1]) \n",
    "    except IndexError:\n",
    "        print ('Index Error')\n",
    "        return (None, None, None)\n",
    "    \n",
    "    total_offset_axis = last_offset * 4 + (8 * 4) \n",
    "    our_matrix = np.random.uniform(min_value, lower_first, (128, int(total_offset_axis))) \n",
    "    # creates matrix and fills with (-1, -0.3), this values will represent the rest.\n",
    "    \n",
    "    for (note, duration, offset) in zip(notes, durations, offsets):\n",
    "        how_many = int(float(duration)/0.25) # indicates time duration for single note.\n",
    "       \n",
    "        first_touch = np.random.uniform(upper_second, max_value, 1)\n",
    "        continuation = np.random.uniform(lower_second, upper_first, 1)\n",
    "        \n",
    "        if ('.' not in str(note)): # It is not chord. Single note.\n",
    "            our_matrix[note, int(offset * 4)] = first_touch\n",
    "            our_matrix[note, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "\n",
    "        else: # For chord\n",
    "            chord_notes_str = [note for note in note.split('.')] \n",
    "            chord_notes_float = list(map(int, chord_notes_str)) # Take notes in chord one by one\n",
    "\n",
    "            for chord_note_float in chord_notes_float:\n",
    "                our_matrix[chord_note_float, int(offset * 4)] = first_touch\n",
    "                our_matrix[chord_note_float, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "                \n",
    "    return our_matrix\n",
    "\n",
    "def check_float(duration): # This function fix the issue which comes from some note's duration. \n",
    "                           # For instance some note has duration like 14/3 or 7/3. \n",
    "    if ('/' in duration):\n",
    "        numerator = float(duration.split('/')[0])\n",
    "        denominator = float(duration.split('/')[1])\n",
    "        duration = str(float(numerator/denominator))\n",
    "    return duration\n",
    "\n",
    "def midi_to_matrix(filename, length=250): # Convert midi file to matrix for DL architecture.\n",
    "    \n",
    "    midi = converter.parse(filename)\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    try :\n",
    "        parts = music21.instrument.partitionByInstrument(midi)\n",
    "    except TypeError:\n",
    "        print ('Type error.')\n",
    "        return None\n",
    "      \n",
    "    instrument_names = []\n",
    "    \n",
    "    try:\n",
    "        for instrument in parts: # Learn names of instruments.\n",
    "            name = (str(instrument).split(' ')[-1])[:-1]\n",
    "            instrument_names.append(name)\n",
    "    \n",
    "    except TypeError:\n",
    "        print ('Type is not iterable.')\n",
    "        return None\n",
    "    \n",
    "    # Just take piano part. For the future works, we can use different instrument.\n",
    "    try:\n",
    "        piano_index = instrument_names.index('Piano')\n",
    "    except ValueError:\n",
    "        print ('%s have not any Piano part' %(filename))\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    notes_to_parse = parts.parts[piano_index].recurse()\n",
    "    \n",
    "    duration_piano = float(check_float((str(notes_to_parse._getDuration()).split(' ')[-1])[:-1]))\n",
    "\n",
    "    durations = []\n",
    "    notes = []\n",
    "    offsets = []\n",
    "    \n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note): # If it is single note\n",
    "            notes.append(note_to_int(str(element.pitch))) # Append note's integer value to \"notes\" list.\n",
    "            duration = str(element.duration)[27:-1] \n",
    "            durations.append(check_float(duration)) \n",
    "            offsets.append(element.offset)\n",
    "\n",
    "        elif isinstance(element, chord.Chord): # If it is chord\n",
    "            notes.append('.'.join(str(note_to_int(str(n)))\n",
    "                                  for n in element.pitches))\n",
    "            duration = str(element.duration)[27:-1]\n",
    "            durations.append(check_float(duration))\n",
    "            offsets.append(element.offset)\n",
    "\n",
    "    \n",
    "    \n",
    "    our_matrix = notes_to_matrix(notes, durations, offsets)\n",
    "    \n",
    "    try:\n",
    "        freq, time = our_matrix.shape\n",
    "    except AttributeError:\n",
    "        print (\"'tuple' object has no attribute 'shape'\")\n",
    "        return None\n",
    "            \n",
    "    if (time >= length):\n",
    "        return (our_matrix[:,:length]) # We have to set all individual note matrix to same shape for Generative DL.\n",
    "    else:\n",
    "        print ('%s have not enough duration' %(filename))\n",
    "\n",
    "def int_to_note(integer):\n",
    "    # Convert pitch value to the note which is a letter form. \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    octave_detector = (integer // 12) \n",
    "    base_name_detector = (integer % 12) \n",
    "    note = note_base_name[base_name_detector] + str((int(octave_detector))-1)\n",
    "    if ('-' in note):\n",
    "      note = note_base_name[base_name_detector] + str(0)\n",
    "      return note\n",
    "    return note\n",
    "\n",
    "# PAY ATTENTION. From matrix form to midi form, I have to indicate first touch, continuation and rest with unique numbers.\n",
    "# I choose -1.0 for rest , 0 for continuation and 1 for first touch.\n",
    "\n",
    "lower_bound = (lower_first + lower_second) / 2\n",
    "upper_bound = (upper_first + upper_second) / 2\n",
    "\n",
    "def converter_func(arr,first_touch = 1.0, continuation = 0.0, lower_bound = lower_bound, upper_bound = upper_bound):\n",
    "    \n",
    "    np.place(arr, arr < lower_bound, -1.0)\n",
    "    np.place(arr, (lower_bound <= arr) & (arr < upper_bound), 0.0)\n",
    "    np.place(arr, arr >= upper_bound, 1.0)\n",
    "    return arr\n",
    "\n",
    "def how_many_repetitive_func(array, from_where=0, continuation=0.0):\n",
    "    new_array = array[from_where:]\n",
    "    count_repetitive = 1 \n",
    "    for i in new_array:\n",
    "        if (i != continuation):\n",
    "            return (count_repetitive)\n",
    "        else:\n",
    "            count_repetitive += 1\n",
    "    return (count_repetitive)\n",
    "\n",
    "def matrix_to_midi(matrix, random=1):\n",
    "    first_touch = 1.0\n",
    "    continuation = 0.0\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    output_notes = []\n",
    "    offset = 0\n",
    "        \n",
    "    # Delete rows until the row which include 'first_touch'\n",
    "    how_many_in_start_zeros = 0\n",
    "    for x_axis_num in range(x_axis):\n",
    "        one_time_interval = matrix[:,x_axis_num] # Values in a column.\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_start_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    how_many_in_end_zeros = 0\n",
    "    for x_axis_num in range(x_axis-1,0,-1):\n",
    "        one_time_interval = matrix[:,x_axis_num] # values in a column\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_end_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    print ('How many rows for non-start note at beginning:', how_many_in_start_zeros)\n",
    "    print ('How many rows for non-start note at end:', how_many_in_end_zeros)\n",
    "\n",
    "    matrix = matrix[:,how_many_in_start_zeros:]\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    print (y_axis, x_axis)\n",
    "\n",
    "    for y_axis_num in range(y_axis):\n",
    "        one_freq_interval = matrix[y_axis_num,:] # Values in a row.\n",
    "        \n",
    "        one_freq_interval_norm = converter_func(one_freq_interval)\n",
    "        \n",
    "        i = 0        \n",
    "        offset = 0\n",
    "        \n",
    "        if (random):\n",
    "          \n",
    "          while (i < len(one_freq_interval)):\n",
    "              how_many_repetitive = 0\n",
    "              temp_i = i\n",
    "              if (one_freq_interval_norm[i] == first_touch):\n",
    "                  how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                  i += how_many_repetitive \n",
    "\n",
    "              if (how_many_repetitive > 0):\n",
    "                  random_num = np.random.randint(3,6)\n",
    "                  new_note = note.Note(int_to_note(y_axis_num),duration=duration.Duration(0.25*random_num*how_many_repetitive))\n",
    "                  new_note.offset = 0.25*temp_i*2\n",
    "                  new_note.storedInstrument = instrument.Piano()\n",
    "                  output_notes.append(new_note)\n",
    "              else:\n",
    "                  i += 1\n",
    "        \n",
    "          \n",
    "        else:\n",
    "          \n",
    "          while (i < len(one_freq_interval)):\n",
    "              how_many_repetitive = 0\n",
    "              temp_i = i\n",
    "              if (one_freq_interval_norm[i] == first_touch):\n",
    "                  how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                  i += how_many_repetitive \n",
    "\n",
    "              if (how_many_repetitive > 0):\n",
    "                  new_note = note.Note(int_to_note(y_axis_num),duration=duration.Duration(0.25*how_many_repetitive))\n",
    "                  new_note.offset = 0.25*temp_i\n",
    "                  new_note.storedInstrument = instrument.Piano()\n",
    "                  output_notes.append(new_note)\n",
    "              else:\n",
    "                  i += 1\n",
    "        \n",
    "    return output_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20500, 128)\n",
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0. -0.  0. ...  0.  0.  0.]\n",
      " [-0. -0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "midis_array = './midis_array_schumann.npy'\n",
    "midis_array_raw = np.load(midis_array)\n",
    "\n",
    "midis_array = np.transpose(midis_array_raw, (0, 2, 1)) \n",
    "midis_array.shape\n",
    "\n",
    "midis_array = np.asarray(midis_array)\n",
    "midis_array = np.reshape(midis_array,(-1,128))\n",
    "\n",
    "midis_array.shape\n",
    "print(midis_array.shape)\n",
    "print(midis_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 15 # how many column will take account to predict next column.\n",
    "step = 1 # step size.\n",
    "\n",
    "previous_full = []\n",
    "predicted_full = []\n",
    "\n",
    "for i in range (0, midis_array.shape[0]-max_len, step):\n",
    "    prev = midis_array[i:i+max_len,...] # take max_len column.\n",
    "    pred = midis_array[i+max_len,...] # take (max_len)th column.\n",
    "    previous_full.append(prev)\n",
    "    predicted_full.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_full = np.asarray(previous_full).astype('float64')\n",
    "predicted_full = np.asarray (predicted_full).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20485, 15, 128)\n",
      "(20485, 128)\n"
     ]
    }
   ],
   "source": [
    "num_of_sample, max_len, freq = previous_full.shape\n",
    "\n",
    "print (previous_full.shape)\n",
    "print (predicted_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our Deep Learning Architecture\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.layers.advanced_activations import *\n",
    "\n",
    "midi_shape = (max_len, 128)\n",
    "\n",
    "input_midi = keras.Input(midi_shape)\n",
    "\n",
    "x = layers.LSTM(1024, return_sequences=True, unit_forget_bias=True)(input_midi)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# compute importance for each step\n",
    "attention = layers.Dense(1, activation='tanh')(x)\n",
    "attention = layers.Flatten()(attention)\n",
    "attention = layers.Activation('softmax')(attention)\n",
    "attention = layers.RepeatVector(1024)(attention)\n",
    "attention = layers.Permute([2, 1])(attention)\n",
    "\n",
    "multiplied = layers.Multiply()([x, attention])\n",
    "sent_representation = layers.Dense(512)(multiplied)\n",
    "\n",
    "\n",
    "x = layers.Dense(512)(sent_representation)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "x = layers.LSTM(512, return_sequences=True, unit_forget_bias=True)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "\n",
    "# compute importance for each step\n",
    "attention = layers.Dense(1, activation='tanh')(x)\n",
    "attention = layers.Flatten()(attention)\n",
    "attention = layers.Activation('softmax')(attention)\n",
    "attention = layers.RepeatVector(512)(attention)\n",
    "attention = layers.Permute([2, 1])(attention)\n",
    "\n",
    "multiplied = layers.Multiply()([x, attention])\n",
    "sent_representation = layers.Dense(256)(multiplied)\n",
    "\n",
    "\n",
    "x = layers.Dense(256)(sent_representation)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "\n",
    "x = layers.LSTM(128, unit_forget_bias=True)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(128, activation='softmax')(x) \n",
    "\n",
    "model = Model(input_midi, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 15, 128)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 15, 1024)     4722688     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 15, 1024)     0           ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 15, 1024)    4096        ['leaky_re_lu_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 15, 1024)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 15, 1)        1025        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 15)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 15)           0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " repeat_vector_2 (RepeatVector)  (None, 1024, 15)    0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " permute_2 (Permute)            (None, 15, 1024)     0           ['repeat_vector_2[0][0]']        \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 15, 1024)     0           ['dropout_5[0][0]',              \n",
      "                                                                  'permute_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 15, 512)      524800      ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 15, 512)      262656      ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 15, 512)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 15, 512)     2048        ['leaky_re_lu_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 15, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 15, 512)      2099200     ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 15, 512)      0           ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 15, 512)     2048        ['leaky_re_lu_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 15, 512)      0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 15, 1)        513         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 15)           0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 15)           0           ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 512, 15)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " permute_3 (Permute)            (None, 15, 512)      0           ['repeat_vector_3[0][0]']        \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 15, 512)      0           ['dropout_7[0][0]',              \n",
      "                                                                  'permute_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 15, 256)      131328      ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 15, 256)      65792       ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 15, 256)      0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 15, 256)     1024        ['leaky_re_lu_8[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 15, 256)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 128)          197120      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 128)          0           ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 128)         512         ['leaky_re_lu_9[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 128)          0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          16512       ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,031,362\n",
      "Trainable params: 8,026,498\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.00007, momentum=0.0, decay=0.02, nesterov=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.04, amsgrad=False)\n",
    "#optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8, schedule_decay=0.04)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    num_of_top = 15\n",
    "    num_of_first = np.random.randint(1,3)\n",
    "\n",
    "    \n",
    "    preds [0:48] = 0 # eliminate notes with low octaves\n",
    "    preds [100:] = 0 # eliminate notes with very high octaves\n",
    "    \n",
    "    ind = np.argpartition(preds, -1*num_of_top)[-1*num_of_top:]\n",
    "    top_indices_sorted = ind[np.argsort(preds[ind])]\n",
    "    \n",
    "    \n",
    "    array = np.random.uniform(0.0, 0.0, (128)) \n",
    "    array[top_indices_sorted[0:num_of_first]] = 1.0\n",
    "    array[top_indices_sorted[num_of_first:num_of_first+3]] = 0.5\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20485, 15, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "10243/10243 [==============================] - 97s 9ms/step - loss: 6.9448\n",
      "Epoch: 2\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.8422\n",
      "Epoch: 3\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.8222\n",
      "Epoch: 4\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7925\n",
      "Epoch: 5\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7714\n",
      "Epoch: 6\n",
      "10243/10243 [==============================] - 93s 9ms/step - loss: 6.7595\n",
      "Epoch: 7\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7624\n",
      "Epoch: 8\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7559\n",
      "Epoch: 9\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7442\n",
      "Epoch: 10\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7240\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 11\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7429\n",
      "Epoch: 12\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7466\n",
      "Epoch: 13\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7294\n",
      "Epoch: 14\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7273\n",
      "Epoch: 15\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7214\n",
      "Epoch: 16\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7335\n",
      "Epoch: 17\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7115\n",
      "Epoch: 18\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7167\n",
      "Epoch: 19\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7050\n",
      "Epoch: 20\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6996\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 21\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7111\n",
      "Epoch: 22\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7024\n",
      "Epoch: 23\n",
      "10243/10243 [==============================] - 93s 9ms/step - loss: 6.7021\n",
      "Epoch: 24\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6991\n",
      "Epoch: 25\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7101\n",
      "Epoch: 26\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6962\n",
      "Epoch: 27\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6977\n",
      "Epoch: 28\n",
      "10243/10243 [==============================] - 93s 9ms/step - loss: 6.7022\n",
      "Epoch: 29\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6940\n",
      "Epoch: 30\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6933\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 31\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.7031\n",
      "Epoch: 32\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6951\n",
      "Epoch: 33\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6955\n",
      "Epoch: 34\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6979\n",
      "Epoch: 35\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6922\n",
      "Epoch: 36\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6954\n",
      "Epoch: 37\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7056\n",
      "Epoch: 38\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6747\n",
      "Epoch: 39\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6775\n",
      "Epoch: 40\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.7023\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 41\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6754\n",
      "Epoch: 42\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6836\n",
      "Epoch: 43\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6986\n",
      "Epoch: 44\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6544\n",
      "Epoch: 45\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6815\n",
      "Epoch: 46\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6943\n",
      "Epoch: 47\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6884\n",
      "Epoch: 48\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6607\n",
      "Epoch: 49\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6866\n",
      "Epoch: 50\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6814\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 51\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6758\n",
      "Epoch: 52\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6849\n",
      "Epoch: 53\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6778\n",
      "Epoch: 54\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6851\n",
      "Epoch: 55\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6727\n",
      "Epoch: 56\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6728\n",
      "Epoch: 57\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6824\n",
      "Epoch: 58\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6848\n",
      "Epoch: 59\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6683\n",
      "Epoch: 60\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6766\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 61\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6661\n",
      "Epoch: 62\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6872\n",
      "Epoch: 63\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6609\n",
      "Epoch: 64\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6833\n",
      "Epoch: 65\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6797\n",
      "Epoch: 66\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6611\n",
      "Epoch: 67\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6755\n",
      "Epoch: 68\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6538\n",
      "Epoch: 69\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6767\n",
      "Epoch: 70\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6802\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 71\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6852\n",
      "Epoch: 72\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6610\n",
      "Epoch: 73\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6731\n",
      "Epoch: 74\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6618\n",
      "Epoch: 75\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6662\n",
      "Epoch: 76\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6717\n",
      "Epoch: 77\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6819\n",
      "Epoch: 78\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6692\n",
      "Epoch: 79\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6683\n",
      "Epoch: 80\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6628\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 81\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6674\n",
      "Epoch: 82\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6753\n",
      "Epoch: 83\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6536\n",
      "Epoch: 84\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6592\n",
      "Epoch: 85\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6672\n",
      "Epoch: 86\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6822\n",
      "Epoch: 87\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6802\n",
      "Epoch: 88\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6668\n",
      "Epoch: 89\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6709\n",
      "Epoch: 90\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6718\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 91\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6610\n",
      "Epoch: 92\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6742\n",
      "Epoch: 93\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6505\n",
      "Epoch: 94\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6798\n",
      "Epoch: 95\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6812\n",
      "Epoch: 96\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6713\n",
      "Epoch: 97\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6608\n",
      "Epoch: 98\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6673\n",
      "Epoch: 99\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6534\n",
      "Epoch: 100\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6769\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 101\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6563\n",
      "Epoch: 102\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6736\n",
      "Epoch: 103\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6750\n",
      "Epoch: 104\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6592\n",
      "Epoch: 105\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6703\n",
      "Epoch: 106\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6659\n",
      "Epoch: 107\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6763\n",
      "Epoch: 108\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6669\n",
      "Epoch: 109\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6794\n",
      "Epoch: 110\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6658\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 111\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6673\n",
      "Epoch: 112\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6663\n",
      "Epoch: 113\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6489\n",
      "Epoch: 114\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6512\n",
      "Epoch: 115\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6753\n",
      "Epoch: 116\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6691\n",
      "Epoch: 117\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6583\n",
      "Epoch: 118\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6664\n",
      "Epoch: 119\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6580\n",
      "Epoch: 120\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6663\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 121\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6387\n",
      "Epoch: 122\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6632\n",
      "Epoch: 123\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6643\n",
      "Epoch: 124\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6701\n",
      "Epoch: 125\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6655\n",
      "Epoch: 126\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6719\n",
      "Epoch: 127\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6689\n",
      "Epoch: 128\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6604\n",
      "Epoch: 129\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6585\n",
      "Epoch: 130\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6517\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 131\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6691\n",
      "Epoch: 132\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6665\n",
      "Epoch: 133\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6526\n",
      "Epoch: 134\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6500\n",
      "Epoch: 135\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6651\n",
      "Epoch: 136\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6537\n",
      "Epoch: 137\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6653\n",
      "Epoch: 138\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6723\n",
      "Epoch: 139\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6639\n",
      "Epoch: 140\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6704\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 141\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6667\n",
      "Epoch: 142\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6732\n",
      "Epoch: 143\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6584\n",
      "Epoch: 144\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6507\n",
      "Epoch: 145\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6641\n",
      "Epoch: 146\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6587\n",
      "Epoch: 147\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6716\n",
      "Epoch: 148\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6473\n",
      "Epoch: 149\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6691\n",
      "Epoch: 150\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6662\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 9\n",
      "How many rows for non-start note at end: 0\n",
      "128 486\n",
      "Epoch: 151\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6654\n",
      "Epoch: 152\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6572\n",
      "Epoch: 153\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6520\n",
      "Epoch: 154\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6564\n",
      "Epoch: 155\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6528\n",
      "Epoch: 156\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6688\n",
      "Epoch: 157\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6530\n",
      "Epoch: 158\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6623\n",
      "Epoch: 159\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6746\n",
      "Epoch: 160\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6598\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 161\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6525\n",
      "Epoch: 162\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6504\n",
      "Epoch: 163\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6539\n",
      "Epoch: 164\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6727\n",
      "Epoch: 165\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6530\n",
      "Epoch: 166\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6617\n",
      "Epoch: 167\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6621\n",
      "Epoch: 168\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6543\n",
      "Epoch: 169\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6642\n",
      "Epoch: 170\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6482\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 7\n",
      "How many rows for non-start note at end: 0\n",
      "128 488\n",
      "Epoch: 171\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6585\n",
      "Epoch: 172\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6570\n",
      "Epoch: 173\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6609\n",
      "Epoch: 174\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6668\n",
      "Epoch: 175\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6625\n",
      "Epoch: 176\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6627\n",
      "Epoch: 177\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6535\n",
      "Epoch: 178\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6692\n",
      "Epoch: 179\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6486\n",
      "Epoch: 180\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6602\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 181\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6746\n",
      "Epoch: 182\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6701\n",
      "Epoch: 183\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6671\n",
      "Epoch: 184\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6620\n",
      "Epoch: 185\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6563\n",
      "Epoch: 186\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6628\n",
      "Epoch: 187\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6684\n",
      "Epoch: 188\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6523\n",
      "Epoch: 189\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6533\n",
      "Epoch: 190\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6539\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 191\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6565\n",
      "Epoch: 192\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6530\n",
      "Epoch: 193\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6644\n",
      "Epoch: 194\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6623\n",
      "Epoch: 195\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6588\n",
      "Epoch: 196\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6428\n",
      "Epoch: 197\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6603\n",
      "Epoch: 198\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6656\n",
      "Epoch: 199\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6663\n",
      "Epoch: 200\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6492\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 201\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6593\n",
      "Epoch: 202\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6502\n",
      "Epoch: 203\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6549\n",
      "Epoch: 204\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6552\n",
      "Epoch: 205\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6549\n",
      "Epoch: 206\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6583\n",
      "Epoch: 207\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6537\n",
      "Epoch: 208\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6470\n",
      "Epoch: 209\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6686\n",
      "Epoch: 210\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6587\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 8\n",
      "How many rows for non-start note at end: 0\n",
      "128 487\n",
      "Epoch: 211\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6609\n",
      "Epoch: 212\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6682\n",
      "Epoch: 213\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6611\n",
      "Epoch: 214\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6552\n",
      "Epoch: 215\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6529\n",
      "Epoch: 216\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6620\n",
      "Epoch: 217\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6688\n",
      "Epoch: 218\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6474\n",
      "Epoch: 219\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6417\n",
      "Epoch: 220\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6538\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 221\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6472\n",
      "Epoch: 222\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6368\n",
      "Epoch: 223\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6488\n",
      "Epoch: 224\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6418\n",
      "Epoch: 225\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6630\n",
      "Epoch: 226\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6507\n",
      "Epoch: 227\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6379\n",
      "Epoch: 228\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6607\n",
      "Epoch: 229\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6591\n",
      "Epoch: 230\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6598\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 231\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6402\n",
      "Epoch: 232\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6728\n",
      "Epoch: 233\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6499\n",
      "Epoch: 234\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6516\n",
      "Epoch: 235\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6620\n",
      "Epoch: 236\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6472\n",
      "Epoch: 237\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6531\n",
      "Epoch: 238\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6528\n",
      "Epoch: 239\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6452\n",
      "Epoch: 240\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6486\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 241\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6646\n",
      "Epoch: 242\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6574\n",
      "Epoch: 243\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6667\n",
      "Epoch: 244\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6448\n",
      "Epoch: 245\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6381\n",
      "Epoch: 246\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6610\n",
      "Epoch: 247\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6684\n",
      "Epoch: 248\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6534\n",
      "Epoch: 249\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6576\n",
      "Epoch: 250\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6510\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 251\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6411\n",
      "Epoch: 252\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6627\n",
      "Epoch: 253\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6526\n",
      "Epoch: 254\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6672\n",
      "Epoch: 255\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6634\n",
      "Epoch: 256\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6576\n",
      "Epoch: 257\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6565\n",
      "Epoch: 258\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6492\n",
      "Epoch: 259\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6632\n",
      "Epoch: 260\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6508\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 261\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6402\n",
      "Epoch: 262\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6469\n",
      "Epoch: 263\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6540\n",
      "Epoch: 264\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6684\n",
      "Epoch: 265\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6528\n",
      "Epoch: 266\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6573\n",
      "Epoch: 267\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6497\n",
      "Epoch: 268\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6621\n",
      "Epoch: 269\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6465\n",
      "Epoch: 270\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6491\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 271\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6640\n",
      "Epoch: 272\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6586\n",
      "Epoch: 273\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6564\n",
      "Epoch: 274\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6412\n",
      "Epoch: 275\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6579\n",
      "Epoch: 276\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6625\n",
      "Epoch: 277\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6432\n",
      "Epoch: 278\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6526\n",
      "Epoch: 279\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6451\n",
      "Epoch: 280\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6643\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 281\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6683\n",
      "Epoch: 282\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6456\n",
      "Epoch: 283\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6484\n",
      "Epoch: 284\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6522\n",
      "Epoch: 285\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6510\n",
      "Epoch: 286\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6497\n",
      "Epoch: 287\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6312\n",
      "Epoch: 288\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6518\n",
      "Epoch: 289\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6359\n",
      "Epoch: 290\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6463\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 291\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6528\n",
      "Epoch: 292\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6564\n",
      "Epoch: 293\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6485\n",
      "Epoch: 294\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6409\n",
      "Epoch: 295\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6417\n",
      "Epoch: 296\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6550\n",
      "Epoch: 297\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6532\n",
      "Epoch: 298\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6384\n",
      "Epoch: 299\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6422\n",
      "Epoch: 300\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6632\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 301\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6523\n",
      "Epoch: 302\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6521\n",
      "Epoch: 303\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6440\n",
      "Epoch: 304\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6371\n",
      "Epoch: 305\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6471\n",
      "Epoch: 306\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6530\n",
      "Epoch: 307\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6335\n",
      "Epoch: 308\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6616\n",
      "Epoch: 309\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6468\n",
      "Epoch: 310\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6554\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 311\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6553\n",
      "Epoch: 312\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6636\n",
      "Epoch: 313\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6697\n",
      "Epoch: 314\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6595\n",
      "Epoch: 315\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6401\n",
      "Epoch: 316\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6636\n",
      "Epoch: 317\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6508\n",
      "Epoch: 318\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6565\n",
      "Epoch: 319\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6421\n",
      "Epoch: 320\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6419\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 321\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6410\n",
      "Epoch: 322\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6448\n",
      "Epoch: 323\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6546\n",
      "Epoch: 324\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6579\n",
      "Epoch: 325\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6590\n",
      "Epoch: 326\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6755\n",
      "Epoch: 327\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6515\n",
      "Epoch: 328\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6648\n",
      "Epoch: 329\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6458\n",
      "Epoch: 330\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6518\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 331\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6796\n",
      "Epoch: 332\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6629\n",
      "Epoch: 333\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6453\n",
      "Epoch: 334\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6570\n",
      "Epoch: 335\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6484\n",
      "Epoch: 336\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6418\n",
      "Epoch: 337\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6523\n",
      "Epoch: 338\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6454\n",
      "Epoch: 339\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6704\n",
      "Epoch: 340\n",
      "10243/10243 [==============================] - 97s 9ms/step - loss: 6.6486\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 341\n",
      "10243/10243 [==============================] - 100s 10ms/step - loss: 6.6502\n",
      "Epoch: 342\n",
      "10243/10243 [==============================] - 98s 10ms/step - loss: 6.6480\n",
      "Epoch: 343\n",
      "10243/10243 [==============================] - 97s 9ms/step - loss: 6.6414\n",
      "Epoch: 344\n",
      "10243/10243 [==============================] - 99s 10ms/step - loss: 6.6444\n",
      "Epoch: 345\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6658\n",
      "Epoch: 346\n",
      "10243/10243 [==============================] - 111s 11ms/step - loss: 6.6674\n",
      "Epoch: 347\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6558\n",
      "Epoch: 348\n",
      "10243/10243 [==============================] - 99s 10ms/step - loss: 6.6497\n",
      "Epoch: 349\n",
      "10243/10243 [==============================] - 108s 11ms/step - loss: 6.6539\n",
      "Epoch: 350\n",
      "10243/10243 [==============================] - 111s 11ms/step - loss: 6.6453\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 489\n",
      "Epoch: 351\n",
      "10243/10243 [==============================] - 111s 11ms/step - loss: 6.6514\n",
      "Epoch: 352\n",
      "10243/10243 [==============================] - 111s 11ms/step - loss: 6.6562\n",
      "Epoch: 353\n",
      "10243/10243 [==============================] - 110s 11ms/step - loss: 6.6397\n",
      "Epoch: 354\n",
      "10243/10243 [==============================] - 110s 11ms/step - loss: 6.6356\n",
      "Epoch: 355\n",
      "10243/10243 [==============================] - 110s 11ms/step - loss: 6.6494\n",
      "Epoch: 356\n",
      "10243/10243 [==============================] - 110s 11ms/step - loss: 6.6583\n",
      "Epoch: 357\n",
      "10243/10243 [==============================] - 111s 11ms/step - loss: 6.6437\n",
      "Epoch: 358\n",
      "10243/10243 [==============================] - 110s 11ms/step - loss: 6.6469\n",
      "Epoch: 359\n",
      "10243/10243 [==============================] - 109s 11ms/step - loss: 6.6582\n",
      "Epoch: 360\n",
      "10243/10243 [==============================] - 108s 11ms/step - loss: 6.6548\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 361\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6435\n",
      "Epoch: 362\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6570\n",
      "Epoch: 363\n",
      "10243/10243 [==============================] - 108s 11ms/step - loss: 6.6505\n",
      "Epoch: 364\n",
      "10243/10243 [==============================] - 108s 11ms/step - loss: 6.6317\n",
      "Epoch: 365\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6560\n",
      "Epoch: 366\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6525\n",
      "Epoch: 367\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6550\n",
      "Epoch: 368\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6657\n",
      "Epoch: 369\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6489\n",
      "Epoch: 370\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6488\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 5\n",
      "How many rows for non-start note at end: 0\n",
      "128 490\n",
      "Epoch: 371\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6588\n",
      "Epoch: 372\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6662\n",
      "Epoch: 373\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6445\n",
      "Epoch: 374\n",
      "10243/10243 [==============================] - 106s 10ms/step - loss: 6.6461\n",
      "Epoch: 375\n",
      "10243/10243 [==============================] - 106s 10ms/step - loss: 6.6507\n",
      "Epoch: 376\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6440\n",
      "Epoch: 377\n",
      "10243/10243 [==============================] - 107s 10ms/step - loss: 6.6409\n",
      "Epoch: 378\n",
      "10243/10243 [==============================] - 106s 10ms/step - loss: 6.6629\n",
      "Epoch: 379\n",
      "10243/10243 [==============================] - 106s 10ms/step - loss: 6.6458\n",
      "Epoch: 380\n",
      "10243/10243 [==============================] - 106s 10ms/step - loss: 6.6520\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 381\n",
      "10243/10243 [==============================] - 101s 10ms/step - loss: 6.6529\n",
      "Epoch: 382\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6423\n",
      "Epoch: 383\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6424\n",
      "Epoch: 384\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6567\n",
      "Epoch: 385\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6625\n",
      "Epoch: 386\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6489\n",
      "Epoch: 387\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6601\n",
      "Epoch: 388\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6615\n",
      "Epoch: 389\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6543\n",
      "Epoch: 390\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6470\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 391\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6589\n",
      "Epoch: 392\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6664\n",
      "Epoch: 393\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6366\n",
      "Epoch: 394\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6433\n",
      "Epoch: 395\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6546\n",
      "Epoch: 396\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6364\n",
      "Epoch: 397\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6455\n",
      "Epoch: 398\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6407\n",
      "Epoch: 399\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6580\n",
      "Epoch: 400\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6551\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 401\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6533\n",
      "Epoch: 402\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6534\n",
      "Epoch: 403\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6419\n",
      "Epoch: 404\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6684\n",
      "Epoch: 405\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6352\n",
      "Epoch: 406\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6513\n",
      "Epoch: 407\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6494\n",
      "Epoch: 408\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6500\n",
      "Epoch: 409\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6450\n",
      "Epoch: 410\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6612\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 411\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6518\n",
      "Epoch: 412\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6295\n",
      "Epoch: 413\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6407\n",
      "Epoch: 414\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6437\n",
      "Epoch: 415\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6589\n",
      "Epoch: 416\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6586\n",
      "Epoch: 417\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6643\n",
      "Epoch: 418\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6407\n",
      "Epoch: 419\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6508\n",
      "Epoch: 420\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6480\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 489\n",
      "Epoch: 421\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6327\n",
      "Epoch: 422\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6663\n",
      "Epoch: 423\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6588\n",
      "Epoch: 424\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6521\n",
      "Epoch: 425\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6530\n",
      "Epoch: 426\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6459\n",
      "Epoch: 427\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6363\n",
      "Epoch: 428\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6536\n",
      "Epoch: 429\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6592\n",
      "Epoch: 430\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6570\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 431\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6401\n",
      "Epoch: 432\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6409\n",
      "Epoch: 433\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6455\n",
      "Epoch: 434\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6693\n",
      "Epoch: 435\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6380\n",
      "Epoch: 436\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6472\n",
      "Epoch: 437\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6428\n",
      "Epoch: 438\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6419\n",
      "Epoch: 439\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6592\n",
      "Epoch: 440\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6463\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 489\n",
      "Epoch: 441\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6493\n",
      "Epoch: 442\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6500\n",
      "Epoch: 443\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6483\n",
      "Epoch: 444\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6566\n",
      "Epoch: 445\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6315\n",
      "Epoch: 446\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6489\n",
      "Epoch: 447\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6431\n",
      "Epoch: 448\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6490\n",
      "Epoch: 449\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6487\n",
      "Epoch: 450\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6678\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 451\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6564\n",
      "Epoch: 452\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6399\n",
      "Epoch: 453\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6510\n",
      "Epoch: 454\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6476\n",
      "Epoch: 455\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6643\n",
      "Epoch: 456\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6369\n",
      "Epoch: 457\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6589\n",
      "Epoch: 458\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6413\n",
      "Epoch: 459\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6654\n",
      "Epoch: 460\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6549\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 461\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6492\n",
      "Epoch: 462\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6497\n",
      "Epoch: 463\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6573\n",
      "Epoch: 464\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6548\n",
      "Epoch: 465\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6527\n",
      "Epoch: 466\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6539\n",
      "Epoch: 467\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6555\n",
      "Epoch: 468\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6538\n",
      "Epoch: 469\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6492\n",
      "Epoch: 470\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6605\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 471\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6523\n",
      "Epoch: 472\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6486\n",
      "Epoch: 473\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6567\n",
      "Epoch: 474\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6433\n",
      "Epoch: 475\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6479\n",
      "Epoch: 476\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6469\n",
      "Epoch: 477\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6575\n",
      "Epoch: 478\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6429\n",
      "Epoch: 479\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6718\n",
      "Epoch: 480\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6435\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 481\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6509\n",
      "Epoch: 482\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6465\n",
      "Epoch: 483\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6520\n",
      "Epoch: 484\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6449\n",
      "Epoch: 485\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6483\n",
      "Epoch: 486\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6555\n",
      "Epoch: 487\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6487\n",
      "Epoch: 488\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6453\n",
      "Epoch: 489\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6489\n",
      "Epoch: 490\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6628\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 491\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6594\n",
      "Epoch: 492\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6551\n",
      "Epoch: 493\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6402\n",
      "Epoch: 494\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6454\n",
      "Epoch: 495\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6379\n",
      "Epoch: 496\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6364\n",
      "Epoch: 497\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6521\n",
      "Epoch: 498\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6583\n",
      "Epoch: 499\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6637\n",
      "Epoch: 500\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6620\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 501\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6568\n",
      "Epoch: 502\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6479\n",
      "Epoch: 503\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6417\n",
      "Epoch: 504\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6513\n",
      "Epoch: 505\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6479\n",
      "Epoch: 506\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6557\n",
      "Epoch: 507\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6513\n",
      "Epoch: 508\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6554\n",
      "Epoch: 509\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6470\n",
      "Epoch: 510\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6712\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 511\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6467\n",
      "Epoch: 512\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6511\n",
      "Epoch: 513\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6499\n",
      "Epoch: 514\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6504\n",
      "Epoch: 515\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6525\n",
      "Epoch: 516\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6509\n",
      "Epoch: 517\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6588\n",
      "Epoch: 518\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6428\n",
      "Epoch: 519\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6510\n",
      "Epoch: 520\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6573\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 521\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6359\n",
      "Epoch: 522\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6510\n",
      "Epoch: 523\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6550\n",
      "Epoch: 524\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6493\n",
      "Epoch: 525\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6296\n",
      "Epoch: 526\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6469\n",
      "Epoch: 527\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6393\n",
      "Epoch: 528\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6455\n",
      "Epoch: 529\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6446\n",
      "Epoch: 530\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6526\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 531\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6322\n",
      "Epoch: 532\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6607\n",
      "Epoch: 533\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6526\n",
      "Epoch: 534\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6487\n",
      "Epoch: 535\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6560\n",
      "Epoch: 536\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6461\n",
      "Epoch: 537\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6484\n",
      "Epoch: 538\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6615\n",
      "Epoch: 539\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6568\n",
      "Epoch: 540\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6574\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 541\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6501\n",
      "Epoch: 542\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6387\n",
      "Epoch: 543\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6450\n",
      "Epoch: 544\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6458\n",
      "Epoch: 545\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6520\n",
      "Epoch: 546\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6508\n",
      "Epoch: 547\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6559\n",
      "Epoch: 548\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6386\n",
      "Epoch: 549\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6595\n",
      "Epoch: 550\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6439\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 551\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6477\n",
      "Epoch: 552\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6584\n",
      "Epoch: 553\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6449\n",
      "Epoch: 554\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6375\n",
      "Epoch: 555\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6596\n",
      "Epoch: 556\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6599\n",
      "Epoch: 557\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6459\n",
      "Epoch: 558\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6413\n",
      "Epoch: 559\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6423\n",
      "Epoch: 560\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6373\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 561\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6451\n",
      "Epoch: 562\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6506\n",
      "Epoch: 563\n",
      "10243/10243 [==============================] - 101s 10ms/step - loss: 6.6405\n",
      "Epoch: 564\n",
      "10243/10243 [==============================] - 99s 10ms/step - loss: 6.6379\n",
      "Epoch: 565\n",
      "10243/10243 [==============================] - 100s 10ms/step - loss: 6.6424\n",
      "Epoch: 566\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6474\n",
      "Epoch: 567\n",
      "10243/10243 [==============================] - 101s 10ms/step - loss: 6.6481\n",
      "Epoch: 568\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6418\n",
      "Epoch: 569\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6305\n",
      "Epoch: 570\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6565\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 571\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6550\n",
      "Epoch: 572\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6597\n",
      "Epoch: 573\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6588\n",
      "Epoch: 574\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6474\n",
      "Epoch: 575\n",
      "10243/10243 [==============================] - 100s 10ms/step - loss: 6.6541\n",
      "Epoch: 576\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6501\n",
      "Epoch: 577\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6584\n",
      "Epoch: 578\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6461\n",
      "Epoch: 579\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6379\n",
      "Epoch: 580\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6438\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 581\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6552\n",
      "Epoch: 582\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6497\n",
      "Epoch: 583\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6376\n",
      "Epoch: 584\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6436\n",
      "Epoch: 585\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6423\n",
      "Epoch: 586\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6529\n",
      "Epoch: 587\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6493\n",
      "Epoch: 588\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6593\n",
      "Epoch: 589\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6592\n",
      "Epoch: 590\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6453\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 591\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6578\n",
      "Epoch: 592\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6352\n",
      "Epoch: 593\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6548\n",
      "Epoch: 594\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6641\n",
      "Epoch: 595\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6540\n",
      "Epoch: 596\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6538\n",
      "Epoch: 597\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6419\n",
      "Epoch: 598\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6695\n",
      "Epoch: 599\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6516\n",
      "Epoch: 600\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6467\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 601\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6486\n",
      "Epoch: 602\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6578\n",
      "Epoch: 603\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6555\n",
      "Epoch: 604\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6616\n",
      "Epoch: 605\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6535\n",
      "Epoch: 606\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6415\n",
      "Epoch: 607\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6374\n",
      "Epoch: 608\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6518\n",
      "Epoch: 609\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6549\n",
      "Epoch: 610\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6692\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 611\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6359\n",
      "Epoch: 612\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6529\n",
      "Epoch: 613\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6315\n",
      "Epoch: 614\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6439\n",
      "Epoch: 615\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6469\n",
      "Epoch: 616\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6467\n",
      "Epoch: 617\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6713\n",
      "Epoch: 618\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6478\n",
      "Epoch: 619\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6373\n",
      "Epoch: 620\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6500\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 621\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6580\n",
      "Epoch: 622\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6530\n",
      "Epoch: 623\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6365\n",
      "Epoch: 624\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6389\n",
      "Epoch: 625\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6618\n",
      "Epoch: 626\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6533\n",
      "Epoch: 627\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6498\n",
      "Epoch: 628\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6537\n",
      "Epoch: 629\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6581\n",
      "Epoch: 630\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6428\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 631\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6543\n",
      "Epoch: 632\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6691\n",
      "Epoch: 633\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6538\n",
      "Epoch: 634\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6491\n",
      "Epoch: 635\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6574\n",
      "Epoch: 636\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6502\n",
      "Epoch: 637\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6374\n",
      "Epoch: 638\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6453\n",
      "Epoch: 639\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6514\n",
      "Epoch: 640\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6420\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 641\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6390\n",
      "Epoch: 642\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6708\n",
      "Epoch: 643\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6635\n",
      "Epoch: 644\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6592\n",
      "Epoch: 645\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6526\n",
      "Epoch: 646\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6519\n",
      "Epoch: 647\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6524\n",
      "Epoch: 648\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6524\n",
      "Epoch: 649\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6573\n",
      "Epoch: 650\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6487\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 651\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6637\n",
      "Epoch: 652\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6417\n",
      "Epoch: 653\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6465\n",
      "Epoch: 654\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6334\n",
      "Epoch: 655\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6511\n",
      "Epoch: 656\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6455\n",
      "Epoch: 657\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6504\n",
      "Epoch: 658\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6460\n",
      "Epoch: 659\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6409\n",
      "Epoch: 660\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6454\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 661\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6361\n",
      "Epoch: 662\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6511\n",
      "Epoch: 663\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6431\n",
      "Epoch: 664\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6536\n",
      "Epoch: 665\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6676\n",
      "Epoch: 666\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6564\n",
      "Epoch: 667\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6547\n",
      "Epoch: 668\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6503\n",
      "Epoch: 669\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6629\n",
      "Epoch: 670\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6545\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 671\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6364\n",
      "Epoch: 672\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6539\n",
      "Epoch: 673\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6365\n",
      "Epoch: 674\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6401\n",
      "Epoch: 675\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6407\n",
      "Epoch: 676\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6559\n",
      "Epoch: 677\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6532\n",
      "Epoch: 678\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6515\n",
      "Epoch: 679\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6556\n",
      "Epoch: 680\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6383\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 681\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6450\n",
      "Epoch: 682\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6532\n",
      "Epoch: 683\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6589\n",
      "Epoch: 684\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6510\n",
      "Epoch: 685\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6337\n",
      "Epoch: 686\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6570\n",
      "Epoch: 687\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6429\n",
      "Epoch: 688\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6458\n",
      "Epoch: 689\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6528\n",
      "Epoch: 690\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6462\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 691\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6384\n",
      "Epoch: 692\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6659\n",
      "Epoch: 693\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6535\n",
      "Epoch: 694\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6514\n",
      "Epoch: 695\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6562\n",
      "Epoch: 696\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6390\n",
      "Epoch: 697\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6460\n",
      "Epoch: 698\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6577\n",
      "Epoch: 699\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6451\n",
      "Epoch: 700\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6707\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 701\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6412\n",
      "Epoch: 702\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6592\n",
      "Epoch: 703\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6491\n",
      "Epoch: 704\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6526\n",
      "Epoch: 705\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6527\n",
      "Epoch: 706\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6563\n",
      "Epoch: 707\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6497\n",
      "Epoch: 708\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6542\n",
      "Epoch: 709\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6565\n",
      "Epoch: 710\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6410\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 711\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6579\n",
      "Epoch: 712\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6549\n",
      "Epoch: 713\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6566\n",
      "Epoch: 714\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6338\n",
      "Epoch: 715\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6565\n",
      "Epoch: 716\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6541\n",
      "Epoch: 717\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6478\n",
      "Epoch: 718\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6447\n",
      "Epoch: 719\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6418\n",
      "Epoch: 720\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6468\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 721\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6451\n",
      "Epoch: 722\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6424\n",
      "Epoch: 723\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6532\n",
      "Epoch: 724\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6364\n",
      "Epoch: 725\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6457\n",
      "Epoch: 726\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6587\n",
      "Epoch: 727\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6527\n",
      "Epoch: 728\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6418\n",
      "Epoch: 729\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6518\n",
      "Epoch: 730\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6363\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 731\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6637\n",
      "Epoch: 732\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6479\n",
      "Epoch: 733\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6515\n",
      "Epoch: 734\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6486\n",
      "Epoch: 735\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6578\n",
      "Epoch: 736\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6684\n",
      "Epoch: 737\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6487\n",
      "Epoch: 738\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6479\n",
      "Epoch: 739\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6459\n",
      "Epoch: 740\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6358\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 741\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6525\n",
      "Epoch: 742\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6512\n",
      "Epoch: 743\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6466\n",
      "Epoch: 744\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6434\n",
      "Epoch: 745\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6413\n",
      "Epoch: 746\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6378\n",
      "Epoch: 747\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6435\n",
      "Epoch: 748\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6374\n",
      "Epoch: 749\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6519\n",
      "Epoch: 750\n",
      "10243/10243 [==============================] - 94s 9ms/step - loss: 6.6667\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 751\n",
      "10243/10243 [==============================] - 99s 10ms/step - loss: 6.6491\n",
      "Epoch: 752\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6510\n",
      "Epoch: 753\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6559\n",
      "Epoch: 754\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6445\n",
      "Epoch: 755\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6331\n",
      "Epoch: 756\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6534\n",
      "Epoch: 757\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6532\n",
      "Epoch: 758\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6459\n",
      "Epoch: 759\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6497\n",
      "Epoch: 760\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6408\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 5\n",
      "How many rows for non-start note at end: 0\n",
      "128 490\n",
      "Epoch: 761\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6514\n",
      "Epoch: 762\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6392\n",
      "Epoch: 763\n",
      "10243/10243 [==============================] - 106s 10ms/step - loss: 6.6577\n",
      "Epoch: 764\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6498\n",
      "Epoch: 765\n",
      "10243/10243 [==============================] - 104s 10ms/step - loss: 6.6323\n",
      "Epoch: 766\n",
      "10243/10243 [==============================] - 104s 10ms/step - loss: 6.6501\n",
      "Epoch: 767\n",
      "10243/10243 [==============================] - 104s 10ms/step - loss: 6.6390\n",
      "Epoch: 768\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6415\n",
      "Epoch: 769\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6448\n",
      "Epoch: 770\n",
      "10243/10243 [==============================] - 102s 10ms/step - loss: 6.6578\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 771\n",
      "10243/10243 [==============================] - 103s 10ms/step - loss: 6.6482\n",
      "Epoch: 772\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6544\n",
      "Epoch: 773\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6371\n",
      "Epoch: 774\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6450\n",
      "Epoch: 775\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6555\n",
      "Epoch: 776\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6481\n",
      "Epoch: 777\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6480\n",
      "Epoch: 778\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6341\n",
      "Epoch: 779\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6474\n",
      "Epoch: 780\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6580\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 781\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6422\n",
      "Epoch: 782\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6505\n",
      "Epoch: 783\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6517\n",
      "Epoch: 784\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6434\n",
      "Epoch: 785\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6366\n",
      "Epoch: 786\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6549\n",
      "Epoch: 787\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6589\n",
      "Epoch: 788\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6550\n",
      "Epoch: 789\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6466\n",
      "Epoch: 790\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6524\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 15\n",
      "How many rows for non-start note at end: 0\n",
      "128 480\n",
      "Epoch: 791\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6579\n",
      "Epoch: 792\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6557\n",
      "Epoch: 793\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6426\n",
      "Epoch: 794\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6371\n",
      "Epoch: 795\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6497\n",
      "Epoch: 796\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6587\n",
      "Epoch: 797\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6479\n",
      "Epoch: 798\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6435\n",
      "Epoch: 799\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6513\n",
      "Epoch: 800\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6416\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 801\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6489\n",
      "Epoch: 802\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6546\n",
      "Epoch: 803\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6444\n",
      "Epoch: 804\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6415\n",
      "Epoch: 805\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6417\n",
      "Epoch: 806\n",
      "10243/10243 [==============================] - 96s 9ms/step - loss: 6.6390\n",
      "Epoch: 807\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6419\n",
      "Epoch: 808\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6582\n",
      "Epoch: 809\n",
      "10243/10243 [==============================] - 95s 9ms/step - loss: 6.6484\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "epoch_total = 810\n",
    "batch_size = 2\n",
    "\n",
    "for epoch in range(1, epoch_total): # Train model with epoch_total \n",
    "    print('Epoch:', epoch)\n",
    "    model.fit(previous_full, predicted_full, batch_size=batch_size, epochs=1,\n",
    "              shuffle=True) # Fit model for 1 iteration.\n",
    "    \n",
    "    start_index = random.randint(0, len(midis_array)- max_len - 1)\n",
    "    \n",
    "    generated_midi = midis_array[start_index: start_index + max_len]\n",
    "        \n",
    "    if ((epoch%10) == 0):\n",
    "      model.save_weights('my_model_weights.h5')\n",
    "\n",
    "      for temperature in [1.2]:\n",
    "          print('------ temperature:', temperature)\n",
    "\n",
    "          for i in range(480):\n",
    "              samples = generated_midi[i:]\n",
    "              expanded_samples = np.expand_dims(samples, axis=0)\n",
    "              preds = model.predict(expanded_samples, verbose=0)[0]\n",
    "              preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "              next_array = sample(preds, temperature)\n",
    "              \n",
    "              midi_list = []\n",
    "              midi_list.append(generated_midi)\n",
    "              midi_list.append(next_array)\n",
    "              generated_midi = np.vstack(midi_list)\n",
    "              \n",
    "\n",
    "          generated_midi_final = np.transpose(generated_midi,(1,0))\n",
    "          output_notes = matrix_to_midi(generated_midi_final, random=0)\n",
    "          midi_stream = stream.Stream(output_notes)\n",
    "          midi_file_name = ('lstm_out_{}_{}.mid'.format(epoch, temperature))\n",
    "          midi_stream.write('midi', fp=midi_file_name)\n",
    "          parsed = converter.parse(midi_file_name)\n",
    "          for part in parsed.parts:\n",
    "              part.insert(0, instrument.Piano())\n",
    "          parsed.write('midi', fp=midi_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lstm weights: [array([[ 0.02333261, -0.10485751, -0.10131275, ...,  0.00990351,\n",
      "        -0.03125001,  0.12339676],\n",
      "       [ 0.14829393, -0.05466122,  0.04725698, ..., -0.08060627,\n",
      "         0.05929416,  0.07555886],\n",
      "       [ 0.07187705, -0.04670323,  0.1309292 , ..., -0.05343951,\n",
      "         0.09478994,  0.13102056],\n",
      "       ...,\n",
      "       [ 0.12698588, -0.14954616,  0.13529167, ...,  0.03402999,\n",
      "        -0.09410318, -0.05303695],\n",
      "       [-0.04359978,  0.07993072, -0.04223773, ..., -0.12489647,\n",
      "        -0.12899819, -0.1187452 ],\n",
      "       [ 0.04494443,  0.0595253 ,  0.03311849, ..., -0.04768447,\n",
      "        -0.07518352, -0.10834795]], dtype=float32), array([ 0.00165961,  0.00066715,  0.00160484,  0.0007363 , -0.00113148,\n",
      "        0.0009245 ,  0.00101162,  0.00091086,  0.00095707,  0.00032717,\n",
      "        0.0002748 , -0.00193415, -0.0015702 , -0.00057327,  0.00082011,\n",
      "        0.00029306, -0.00251859, -0.00352363, -0.00028736, -0.00438809,\n",
      "       -0.00200749, -0.00051128, -0.00258809, -0.00012851, -0.00049244,\n",
      "       -0.00356866, -0.0032917 , -0.00051644, -0.00012342, -0.00122065,\n",
      "       -0.00280428,  0.00471731, -0.0112647 ,  0.00065279, -0.01423985,\n",
      "        0.00127141,  0.00167475, -0.0106097 ,  0.00391953, -0.01562618,\n",
      "        0.00255652,  0.00474985, -0.01442053,  0.005215  , -0.01495444,\n",
      "        0.00530623, -0.01644463,  0.00406846,  0.00777744, -0.01564588,\n",
      "        0.00699872, -0.01560073,  0.00695272,  0.00757375, -0.01305602,\n",
      "        0.00842403, -0.01675854,  0.00949058, -0.01365458,  0.00792724,\n",
      "        0.01015097, -0.01289747,  0.00914477, -0.01175093,  0.00988377,\n",
      "        0.00964063, -0.02586222,  0.00794648, -0.02601191,  0.0080737 ,\n",
      "       -0.02595499,  0.01000392,  0.00659877, -0.02612325,  0.00512518,\n",
      "       -0.02601012,  0.00603233,  0.00290454, -0.02730427,  0.00169338,\n",
      "       -0.0245958 , -0.00162569, -0.02569992, -0.00660447, -0.00968889,\n",
      "       -0.02622737, -0.00717685, -0.02624401, -0.01561581, -0.01012804,\n",
      "       -0.02577649, -0.01340795, -0.02522015, -0.01592346, -0.02582404,\n",
      "       -0.02607013, -0.02338087, -0.0265212 , -0.01877702, -0.02533929,\n",
      "       -0.0244152 , -0.0261148 , -0.025829  , -0.02680803, -0.02439307,\n",
      "       -0.02614712, -0.02491494, -0.02575971, -0.02567745, -0.02473466,\n",
      "       -0.02555717, -0.02450446, -0.02560199, -0.02614134, -0.02520407,\n",
      "       -0.02619763, -0.02372366, -0.02599319, -0.02655738, -0.02558629,\n",
      "       -0.02654633, -0.02645574, -0.02665515, -0.02675567, -0.02434483,\n",
      "       -0.02577821, -0.0253508 , -0.02357539], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    lstm_weights = layer.get_weights() # list of numpy arrays\n",
    "\n",
    "print ('Lstm weights:', lstm_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "start_index = random.randint(0, len(midis_array)- max_len - 1)\n",
    "    \n",
    "generated_midi = midis_array[start_index: start_index + max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ temperature: 0.7\n",
      "How many rows for non-start note at beginning: 11\n",
      "How many rows for non-start note at end: 0\n",
      "128 684\n",
      "------ temperature: 2.7\n",
      "How many rows for non-start note at beginning: 11\n",
      "How many rows for non-start note at end: 0\n",
      "128 684\n"
     ]
    }
   ],
   "source": [
    "for temperature in [0.7, 2.7]:\n",
    "        print('------ temperature:', temperature)\n",
    "        generated_midi = midis_array[start_index: start_index + max_len]\n",
    "        for i in range(680):\n",
    "            samples = generated_midi[i:]\n",
    "            expanded_samples = np.expand_dims(samples, axis=0)\n",
    "            preds = model.predict(expanded_samples, verbose=0)[0]\n",
    "            preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "            next_array = sample(preds, temperature)\n",
    "           \n",
    "            midi_list = []\n",
    "            midi_list.append(generated_midi)\n",
    "            midi_list.append(next_array)\n",
    "            generated_midi = np.vstack(midi_list)\n",
    "            \n",
    "\n",
    "        generated_midi_final = np.transpose(generated_midi,(1,0))\n",
    "        output_notes = matrix_to_midi(generated_midi_final, random=1)\n",
    "        midi_stream = stream.Stream(output_notes)\n",
    "        midi_file_name = ('lstm_out_{}.mid'.format(temperature))\n",
    "        midi_stream.write('midi', fp=midi_file_name)\n",
    "        parsed = converter.parse(midi_file_name)\n",
    "        for part in parsed.parts:\n",
    "            part.insert(0, instrument.Piano())\n",
    "        parsed.write('midi', fp=midi_file_name)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05199079 0.0278141  0.0478021  0.03260636 0.02944993 0.02059865\n",
      " 0.02653221 0.02193283 0.13896662 0.02450288 0.02656077 0.01901993\n",
      " 0.01852922 0.01945664 0.0201451  0.01900975 0.01859989 0.01954241\n",
      " 0.01628667 0.0201508 ]\n",
      "max: 0.1389666199684143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zed/.conda/envs/music_base/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "import bottleneck \n",
    "z = -bottleneck.partition(-preds, 20)[:20]\n",
    "print (z)\n",
    "print ('max:', np.max(preds))\n",
    "\n",
    "model.save('my_model.h5')\n",
    "\n",
    "model.save_weights('my_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f14c9d35ad22571b3213e3ba997bc600b8e5211eed475dc9e01b97aa57593897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
