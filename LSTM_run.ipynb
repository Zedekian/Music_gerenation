{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,glob\n",
    "import music21\n",
    "from music21 import *\n",
    "from pathlib import Path\n",
    "environment.set('midiPath', '/usr/bin/musescore3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is GPU active?\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!cat /proc/meminfo \\nfrom tensorflow.python.client import device_lib\\ndevice_lib.list_local_devices()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see information about RAM.\n",
    "'''\n",
    "!cat /proc/meminfo \n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_to_int(note): # converts the note's letter to pitch value which is integer form.\n",
    "    # source: https://musescore.org/en/plugin-development/note-pitch-values\n",
    "    # idea: https://github.com/bspaans/python-mingus/blob/master/mingus/core/notes.py\n",
    "    \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    if ('#-' in note):\n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[3]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('#' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    elif ('-' in note): \n",
    "        first_letter = note[0]\n",
    "        base_value = note_base_name.index(first_letter)\n",
    "        octave = note[2]\n",
    "        value = base_value + 12*(int(octave)-(-1))\n",
    "        \n",
    "    else:\n",
    "        first_letter = note[0]\n",
    "        base_val = note_base_name.index(first_letter)\n",
    "        octave = note[1]\n",
    "        value = base_val + 12*(int(octave)-(-1))\n",
    "        \n",
    "    return value\n",
    "\n",
    "min_value = 0.00\n",
    "lower_first = 0.00\n",
    "#lower_first = 0.1\n",
    "\n",
    "lower_second = 0.5\n",
    "#lower_second = 0.4\n",
    "upper_first = 0.5\n",
    "#upper_first = 0.6\n",
    "\n",
    "upper_second = 1.0\n",
    "#upper_second = 0.8\n",
    "max_value = 1.0\n",
    "\n",
    "def notes_to_matrix(notes, durations, offsets, min_value=min_value, lower_first=lower_first,\n",
    "                    lower_second=lower_second,\n",
    "                    upper_first=upper_first, upper_second=upper_second,\n",
    "                    max_value=max_value):\n",
    "    \n",
    "    # I want to represent my notes in matrix form. X axis will represent time, Y axis will represent pitch values.\n",
    "    # I should normalize my matrix between 0 and 1.\n",
    "    # So that I will represent rest with (min_value, lower_first), continuation with [lower_second, upper_first]\n",
    "    # and first touch with (upper_second, max_value)\n",
    "    # First touch means that you press the note and it cause to 1 time duration playing. Continuation\n",
    "    # represent the continuum of this note playing. \n",
    "    \n",
    "    try:\n",
    "        last_offset = int(offsets[-1]) \n",
    "    except IndexError:\n",
    "        print ('Index Error')\n",
    "        return (None, None, None)\n",
    "    \n",
    "    total_offset_axis = last_offset * 4 + (8 * 4) \n",
    "    our_matrix = np.random.uniform(min_value, lower_first, (128, int(total_offset_axis))) \n",
    "    # creates matrix and fills with (-1, -0.3), this values will represent the rest.\n",
    "    \n",
    "    for (note, duration, offset) in zip(notes, durations, offsets):\n",
    "        how_many = int(float(duration)/0.25) # indicates time duration for single note.\n",
    "       \n",
    "        \n",
    "        # Define difference between single and double note.\n",
    "        # I have choose the value for first touch, the another value for continuation.\n",
    "        # Lets make it randomize\n",
    "        \n",
    "        # I choose to use uniform distrubition. Maybe, you can use another distrubition like Gaussian.\n",
    "        # I will try \n",
    "        first_touch = np.random.uniform(upper_second, max_value, 1)\n",
    "        continuation = np.random.uniform(lower_second, upper_first, 1)\n",
    "        \n",
    "        if ('.' not in str(note)): # It is not chord. Single note.\n",
    "            our_matrix[note, int(offset * 4)] = first_touch\n",
    "            our_matrix[note, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "\n",
    "        else: # For chord\n",
    "            chord_notes_str = [note for note in note.split('.')] \n",
    "            chord_notes_float = list(map(int, chord_notes_str)) # Take notes in chord one by one\n",
    "\n",
    "            for chord_note_float in chord_notes_float:\n",
    "                our_matrix[chord_note_float, int(offset * 4)] = first_touch\n",
    "                our_matrix[chord_note_float, int((offset * 4) + 1) : int((offset * 4) + how_many)] = continuation\n",
    "                \n",
    "    return our_matrix\n",
    "\n",
    "def check_float(duration): # This function fix the issue which comes from some note's duration. \n",
    "                           # For instance some note has duration like 14/3 or 7/3. \n",
    "    if ('/' in duration):\n",
    "        numerator = float(duration.split('/')[0])\n",
    "        denominator = float(duration.split('/')[1])\n",
    "        duration = str(float(numerator/denominator))\n",
    "    return duration\n",
    "\n",
    "def midi_to_matrix(filename, length=250): # Convert midi file to matrix for DL architecture.\n",
    "    \n",
    "    midi = converter.parse(filename)\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    try :\n",
    "        parts = music21.instrument.partitionByInstrument(midi)\n",
    "    except TypeError:\n",
    "        print ('Type error.')\n",
    "        return None\n",
    "      \n",
    "    instrument_names = []\n",
    "    \n",
    "    try:\n",
    "        for instrument in parts: # Learn names of instruments.\n",
    "            name = (str(instrument).split(' ')[-1])[:-1]\n",
    "            instrument_names.append(name)\n",
    "    \n",
    "    except TypeError:\n",
    "        print ('Type is not iterable.')\n",
    "        return None\n",
    "    \n",
    "    # Just take piano part. For the future works, we can use different instrument.\n",
    "    try:\n",
    "        piano_index = instrument_names.index('Piano')\n",
    "    except ValueError:\n",
    "        print ('%s have not any Piano part' %(filename))\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    notes_to_parse = parts.parts[piano_index].recurse()\n",
    "    \n",
    "    duration_piano = float(check_float((str(notes_to_parse._getDuration()).split(' ')[-1])[:-1]))\n",
    "\n",
    "    durations = []\n",
    "    notes = []\n",
    "    offsets = []\n",
    "    \n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note): # If it is single note\n",
    "            notes.append(note_to_int(str(element.pitch))) # Append note's integer value to \"notes\" list.\n",
    "            duration = str(element.duration)[27:-1] \n",
    "            durations.append(check_float(duration)) \n",
    "            offsets.append(element.offset)\n",
    "\n",
    "        elif isinstance(element, chord.Chord): # If it is chord\n",
    "            notes.append('.'.join(str(note_to_int(str(n)))\n",
    "                                  for n in element.pitches))\n",
    "            duration = str(element.duration)[27:-1]\n",
    "            durations.append(check_float(duration))\n",
    "            offsets.append(element.offset)\n",
    "\n",
    "    \n",
    "    \n",
    "    our_matrix = notes_to_matrix(notes, durations, offsets)\n",
    "    \n",
    "    try:\n",
    "        freq, time = our_matrix.shape\n",
    "    except AttributeError:\n",
    "        print (\"'tuple' object has no attribute 'shape'\")\n",
    "        return None\n",
    "            \n",
    "    if (time >= length):\n",
    "        return (our_matrix[:,:length]) # We have to set all individual note matrix to same shape for Generative DL.\n",
    "    else:\n",
    "        print ('%s have not enough duration' %(filename))\n",
    "\n",
    "def int_to_note(integer):\n",
    "    # Convert pitch value to the note which is a letter form. \n",
    "    note_base_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    octave_detector = (integer // 12) \n",
    "    base_name_detector = (integer % 12) \n",
    "    note = note_base_name[base_name_detector] + str((int(octave_detector))-1)\n",
    "    if ('-' in note):\n",
    "      note = note_base_name[base_name_detector] + str(0)\n",
    "      return note\n",
    "    return note\n",
    "\n",
    "# PAY ATTENTION. From matrix form to midi form, I have to indicate first touch, continuation and rest with unique numbers.\n",
    "# I choose -1.0 for rest , 0 for continuation and 1 for first touch.\n",
    "\n",
    "lower_bound = (lower_first + lower_second) / 2\n",
    "upper_bound = (upper_first + upper_second) / 2\n",
    "\n",
    "def converter_func(arr,first_touch = 1.0, continuation = 0.0, lower_bound = lower_bound, upper_bound = upper_bound):\n",
    "    # I can write this function thanks to https://stackoverflow.com/questions/16343752/numpy-where-function-multiple-conditions\n",
    "    # First touch represent start for note, continuation represent continuation for first touch, 0 represent end or rest\n",
    "    np.place(arr, arr < lower_bound, -1.0)\n",
    "    np.place(arr, (lower_bound <= arr) & (arr < upper_bound), 0.0)\n",
    "    np.place(arr, arr >= upper_bound, 1.0)\n",
    "    return arr\n",
    "\n",
    "def how_many_repetitive_func(array, from_where=0, continuation=0.0):\n",
    "    new_array = array[from_where:]\n",
    "    count_repetitive = 1 \n",
    "    for i in new_array:\n",
    "        if (i != continuation):\n",
    "            return (count_repetitive)\n",
    "        else:\n",
    "            count_repetitive += 1\n",
    "    return (count_repetitive)\n",
    "\n",
    "def matrix_to_midi(matrix, random=0):\n",
    "    first_touch = 1.0\n",
    "    continuation = 0.0\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    output_notes = []\n",
    "    offset = 0\n",
    "        \n",
    "    # Delete rows until the row which include 'first_touch'\n",
    "    how_many_in_start_zeros = 0\n",
    "    for x_axis_num in range(x_axis):\n",
    "        one_time_interval = matrix[:,x_axis_num] # Values in a column.\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_start_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    how_many_in_end_zeros = 0\n",
    "    for x_axis_num in range(x_axis-1,0,-1):\n",
    "        one_time_interval = matrix[:,x_axis_num] # values in a column\n",
    "        one_time_interval_norm = converter_func(one_time_interval)\n",
    "        if (first_touch not in one_time_interval_norm):\n",
    "            how_many_in_end_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    print ('How many rows for non-start note at beginning:', how_many_in_start_zeros)\n",
    "    print ('How many rows for non-start note at end:', how_many_in_end_zeros)\n",
    "\n",
    "    matrix = matrix[:,how_many_in_start_zeros:]\n",
    "    y_axis, x_axis = matrix.shape\n",
    "    print (y_axis, x_axis)\n",
    "\n",
    "    for y_axis_num in range(y_axis):\n",
    "        one_freq_interval = matrix[y_axis_num,:] # Values in a row.\n",
    "        \n",
    "        one_freq_interval_norm = converter_func(one_freq_interval)\n",
    "        \n",
    "        i = 0        \n",
    "        offset = 0\n",
    "        \n",
    "        if (random):\n",
    "          \n",
    "          while (i < len(one_freq_interval)):\n",
    "              how_many_repetitive = 0\n",
    "              temp_i = i\n",
    "              if (one_freq_interval_norm[i] == first_touch):\n",
    "                  how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                  i += how_many_repetitive \n",
    "\n",
    "              if (how_many_repetitive > 0):\n",
    "                  random_num = np.random.randint(3,6)\n",
    "                  new_note = note.Note(int_to_note(y_axis_num),duration=duration.Duration(0.25*random_num*how_many_repetitive))\n",
    "                  new_note.offset = 0.25*temp_i*2\n",
    "                  new_note.storedInstrument = instrument.Piano()\n",
    "                  output_notes.append(new_note)\n",
    "              else:\n",
    "                  i += 1\n",
    "        \n",
    "          \n",
    "        else:\n",
    "          \n",
    "          while (i < len(one_freq_interval)):\n",
    "              how_many_repetitive = 0\n",
    "              temp_i = i\n",
    "              if (one_freq_interval_norm[i] == first_touch):\n",
    "                  how_many_repetitive = how_many_repetitive_func(one_freq_interval_norm, from_where=i+1, continuation=continuation)\n",
    "                  i += how_many_repetitive \n",
    "\n",
    "              if (how_many_repetitive > 0):\n",
    "                  new_note = note.Note(int_to_note(y_axis_num),duration=duration.Duration(0.25*how_many_repetitive))\n",
    "                  new_note.offset = 0.25*temp_i\n",
    "                  new_note.storedInstrument = instrument.Piano()\n",
    "                  output_notes.append(new_note)\n",
    "              else:\n",
    "                  i += 1\n",
    "        \n",
    "    return output_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 128)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#midis_array = './midis_array_schumann.npy'\n",
    "midis_array = './midis_array_wikifonia_R50.npy'\n",
    "midis_array_raw = np.load(midis_array)\n",
    "\n",
    "midis_array = np.transpose(midis_array_raw, (0, 2, 1)) \n",
    "midis_array.shape\n",
    "\n",
    "midis_array = np.asarray(midis_array)\n",
    "midis_array = np.reshape(midis_array,(-1,128))\n",
    "\n",
    "midis_array.shape\n",
    "print(midis_array.shape)\n",
    "print(midis_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 18 # how many column will take account to predict next column.\n",
    "step = 1 # step size.\n",
    "\n",
    "previous_full = []\n",
    "predicted_full = []\n",
    "\n",
    "for i in range (0, midis_array.shape[0]-max_len, step):\n",
    "    prev = midis_array[i:i+max_len,...] # take max_len column.\n",
    "    pred = midis_array[i+max_len,...] # take (max_len)th column.\n",
    "    previous_full.append(prev)\n",
    "    predicted_full.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_full = np.asarray(previous_full).astype('float64')\n",
    "predicted_full = np.asarray (predicted_full).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12482, 18, 128)\n",
      "(12482, 128)\n"
     ]
    }
   ],
   "source": [
    "num_of_sample, max_len, freq = previous_full.shape\n",
    "\n",
    "print (previous_full.shape)\n",
    "print (predicted_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 11:38:18.127522: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-07 11:38:18.152374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.179311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.179495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.614996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.615174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.615296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.615410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12129 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-08-07 11:38:18.629822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.630038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.630167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.630492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.630624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.630747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.630909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.631038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-07 11:38:18.631133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12129 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Build our Deep Learning Architecture\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.layers.advanced_activations import *\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5  # 設置使用顯示卡顯存的比例，例如0.5表示使用一半的顯存\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "midi_shape = (max_len, 128)\n",
    "\n",
    "input_midi = keras.Input(midi_shape)\n",
    "\n",
    "x = layers.LSTM(1024, return_sequences=True, unit_forget_bias=True)(input_midi)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# compute importance for each step\n",
    "attention = layers.Dense(1, activation='tanh')(x)\n",
    "attention = layers.Flatten()(attention)\n",
    "attention = layers.Activation('softmax')(attention)\n",
    "attention = layers.RepeatVector(1024)(attention)\n",
    "attention = layers.Permute([2, 1])(attention)\n",
    "\n",
    "multiplied = layers.Multiply()([x, attention])\n",
    "sent_representation = layers.Dense(512)(multiplied)\n",
    "\n",
    "\n",
    "x = layers.Dense(512, kernel_initializer='he_normal')(sent_representation) #+\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "x = layers.LSTM(512, return_sequences=True, unit_forget_bias=True)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "\n",
    "# compute importance for each step\n",
    "attention = layers.Dense(1, activation='tanh')(x)\n",
    "attention = layers.Flatten()(attention)\n",
    "attention = layers.Activation('softmax')(attention)\n",
    "attention = layers.RepeatVector(512)(attention)\n",
    "attention = layers.Permute([2, 1])(attention)\n",
    "\n",
    "multiplied = layers.Multiply()([x, attention])\n",
    "sent_representation = layers.Dense(256)(multiplied)\n",
    "\n",
    "\n",
    "x = layers.Dense(256)(sent_representation)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "\n",
    "x = layers.LSTM(128, unit_forget_bias=True)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization() (x)\n",
    "x = layers.Dropout(0.22)(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(128, activation='softmax')(x) \n",
    "\n",
    "model = Model(input_midi, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 18, 128)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 18, 1024)     4722688     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 18, 1024)     0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 18, 1024)    4096        ['leaky_re_lu[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 18, 1024)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 18, 1)        1025        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 18)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 18)           0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 1024, 18)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 18, 1024)     0           ['repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 18, 1024)     0           ['dropout[0][0]',                \n",
      "                                                                  'permute[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 18, 512)      524800      ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 18, 512)      262656      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 18, 512)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 18, 512)     2048        ['leaky_re_lu_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 18, 512)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 18, 512)      2099200     ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 18, 512)      0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 18, 512)     2048        ['leaky_re_lu_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 18, 512)      0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 18, 1)        513         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 18)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 18)           0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVector)  (None, 512, 18)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute_1 (Permute)            (None, 18, 512)      0           ['repeat_vector_1[0][0]']        \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 18, 512)      0           ['dropout_2[0][0]',              \n",
      "                                                                  'permute_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 18, 256)      131328      ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 18, 256)      65792       ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 18, 256)      0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 18, 256)     1024        ['leaky_re_lu_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 18, 256)      0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 128)          197120      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 128)          0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128)         512         ['leaky_re_lu_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          16512       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,031,362\n",
      "Trainable params: 8,026,498\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.04, amsgrad=False,clipvalue=0.3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    num_of_top = 15\n",
    "    num_of_first = np.random.randint(1,3)\n",
    "\n",
    "    \n",
    "    preds [0:48] = 0 # eliminate notes with low octaves\n",
    "    preds [100:] = 0 # eliminate notes with very high octaves\n",
    "    \n",
    "    ind = np.argpartition(preds, -1*num_of_top)[-1*num_of_top:]\n",
    "    top_indices_sorted = ind[np.argsort(preds[ind])]\n",
    "    \n",
    "    \n",
    "    array = np.random.uniform(0.0, 0.0, (128)) \n",
    "    array[top_indices_sorted[0:num_of_first]] = 1.0\n",
    "    array[top_indices_sorted[num_of_first:num_of_first+3]] = 0.5\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12482, 18, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 11:38:24.644897: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2023-08-07 11:38:25.568805: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 7s 17ms/step - loss: 3.7060\n",
      "Epoch: 2\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.3854\n",
      "Epoch: 3\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.3016\n",
      "Epoch: 4\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.2513\n",
      "Epoch: 5\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.2137\n",
      "Epoch: 6\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.1791\n",
      "Epoch: 7\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.1596\n",
      "Epoch: 8\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.1460\n",
      "Epoch: 9\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.1095\n",
      "Epoch: 10\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.1201\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 11\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0926\n",
      "Epoch: 12\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0833\n",
      "Epoch: 13\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0752\n",
      "Epoch: 14\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0726\n",
      "Epoch: 15\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0617\n",
      "Epoch: 16\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0539\n",
      "Epoch: 17\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0524\n",
      "Epoch: 18\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0532\n",
      "Epoch: 19\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0406\n",
      "Epoch: 20\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0381\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 21\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0317\n",
      "Epoch: 22\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0245\n",
      "Epoch: 23\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0379\n",
      "Epoch: 24\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0215\n",
      "Epoch: 25\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0169\n",
      "Epoch: 26\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0051\n",
      "Epoch: 27\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 3.0126\n",
      "Epoch: 28\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 3.0101\n",
      "Epoch: 29\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9990\n",
      "Epoch: 30\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9990\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 31\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 2.9899\n",
      "Epoch: 32\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9913\n",
      "Epoch: 33\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9903\n",
      "Epoch: 34\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9908\n",
      "Epoch: 35\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9841\n",
      "Epoch: 36\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9830\n",
      "Epoch: 37\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9777\n",
      "Epoch: 38\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9708\n",
      "Epoch: 39\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9753\n",
      "Epoch: 40\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9760\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 41\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9591\n",
      "Epoch: 42\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9764\n",
      "Epoch: 43\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9594\n",
      "Epoch: 44\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9732\n",
      "Epoch: 45\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9606\n",
      "Epoch: 46\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9516\n",
      "Epoch: 47\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9621\n",
      "Epoch: 48\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9418\n",
      "Epoch: 49\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9496\n",
      "Epoch: 50\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9465\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 11\n",
      "How many rows for non-start note at end: 0\n",
      "128 487\n",
      "Epoch: 51\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9482\n",
      "Epoch: 52\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9458\n",
      "Epoch: 53\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9481\n",
      "Epoch: 54\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9507\n",
      "Epoch: 55\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9448\n",
      "Epoch: 56\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9450\n",
      "Epoch: 57\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9433\n",
      "Epoch: 58\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9403\n",
      "Epoch: 59\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9375\n",
      "Epoch: 60\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9365\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 11\n",
      "How many rows for non-start note at end: 0\n",
      "128 487\n",
      "Epoch: 61\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9317\n",
      "Epoch: 62\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9313\n",
      "Epoch: 63\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9416\n",
      "Epoch: 64\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9339\n",
      "Epoch: 65\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9300\n",
      "Epoch: 66\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9326\n",
      "Epoch: 67\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9288\n",
      "Epoch: 68\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9313\n",
      "Epoch: 69\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9315\n",
      "Epoch: 70\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9214\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 71\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9231\n",
      "Epoch: 72\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9204\n",
      "Epoch: 73\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9139\n",
      "Epoch: 74\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9135\n",
      "Epoch: 75\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.9272\n",
      "Epoch: 76\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9127\n",
      "Epoch: 77\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9091\n",
      "Epoch: 78\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9132\n",
      "Epoch: 79\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9184\n",
      "Epoch: 80\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9038\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 5\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 81\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9157\n",
      "Epoch: 82\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9128\n",
      "Epoch: 83\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9082\n",
      "Epoch: 84\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9102\n",
      "Epoch: 85\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9077\n",
      "Epoch: 86\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9113\n",
      "Epoch: 87\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9041\n",
      "Epoch: 88\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.9077\n",
      "Epoch: 89\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9032\n",
      "Epoch: 90\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9006\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 91\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9072\n",
      "Epoch: 92\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9064\n",
      "Epoch: 93\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8960\n",
      "Epoch: 94\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9084\n",
      "Epoch: 95\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9074\n",
      "Epoch: 96\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9003\n",
      "Epoch: 97\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9005\n",
      "Epoch: 98\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8969\n",
      "Epoch: 99\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8932\n",
      "Epoch: 100\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8847\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 101\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8894\n",
      "Epoch: 102\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8910\n",
      "Epoch: 103\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8951\n",
      "Epoch: 104\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.9007\n",
      "Epoch: 105\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.9019\n",
      "Epoch: 106\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8868\n",
      "Epoch: 107\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8889\n",
      "Epoch: 108\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8855\n",
      "Epoch: 109\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8915\n",
      "Epoch: 110\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8895\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 111\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8868\n",
      "Epoch: 112\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8949\n",
      "Epoch: 113\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8946\n",
      "Epoch: 114\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8833\n",
      "Epoch: 115\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8881\n",
      "Epoch: 116\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8770\n",
      "Epoch: 117\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8857\n",
      "Epoch: 118\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8821\n",
      "Epoch: 119\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8709\n",
      "Epoch: 120\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8819\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 121\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8764\n",
      "Epoch: 122\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8819\n",
      "Epoch: 123\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8847\n",
      "Epoch: 124\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8854\n",
      "Epoch: 125\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8825\n",
      "Epoch: 126\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8777\n",
      "Epoch: 127\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8806\n",
      "Epoch: 128\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8799\n",
      "Epoch: 129\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8809\n",
      "Epoch: 130\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8839\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 131\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8786\n",
      "Epoch: 132\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8775\n",
      "Epoch: 133\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8722\n",
      "Epoch: 134\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8818\n",
      "Epoch: 135\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8738\n",
      "Epoch: 136\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8691\n",
      "Epoch: 137\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8678\n",
      "Epoch: 138\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8746\n",
      "Epoch: 139\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8680\n",
      "Epoch: 140\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8789\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 11\n",
      "How many rows for non-start note at end: 0\n",
      "128 487\n",
      "Epoch: 141\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8645\n",
      "Epoch: 142\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8601\n",
      "Epoch: 143\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8705\n",
      "Epoch: 144\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8765\n",
      "Epoch: 145\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8676\n",
      "Epoch: 146\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8518\n",
      "Epoch: 147\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8645\n",
      "Epoch: 148\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8684\n",
      "Epoch: 149\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.8715\n",
      "Epoch: 150\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8626\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 151\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8631\n",
      "Epoch: 152\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8645\n",
      "Epoch: 153\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.8630\n",
      "Epoch: 154\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8565\n",
      "Epoch: 155\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8625\n",
      "Epoch: 156\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8745\n",
      "Epoch: 157\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8558\n",
      "Epoch: 158\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8642\n",
      "Epoch: 159\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8676\n",
      "Epoch: 160\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8560\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 161\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8665\n",
      "Epoch: 162\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8703\n",
      "Epoch: 163\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8604\n",
      "Epoch: 164\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8703\n",
      "Epoch: 165\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8606\n",
      "Epoch: 166\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8597\n",
      "Epoch: 167\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8515\n",
      "Epoch: 168\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8614\n",
      "Epoch: 169\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8586\n",
      "Epoch: 170\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8526\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 171\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8623\n",
      "Epoch: 172\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8555\n",
      "Epoch: 173\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8589\n",
      "Epoch: 174\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8581\n",
      "Epoch: 175\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8461\n",
      "Epoch: 176\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.8535\n",
      "Epoch: 177\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8572\n",
      "Epoch: 178\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8529\n",
      "Epoch: 179\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8539\n",
      "Epoch: 180\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8501\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 181\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8594\n",
      "Epoch: 182\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8550\n",
      "Epoch: 183\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8563\n",
      "Epoch: 184\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8498\n",
      "Epoch: 185\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8542\n",
      "Epoch: 186\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8487\n",
      "Epoch: 187\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8443\n",
      "Epoch: 188\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8516\n",
      "Epoch: 189\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8478\n",
      "Epoch: 190\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8497\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 191\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8562\n",
      "Epoch: 192\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8522\n",
      "Epoch: 193\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8380\n",
      "Epoch: 194\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8493\n",
      "Epoch: 195\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8478\n",
      "Epoch: 196\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8428\n",
      "Epoch: 197\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8453\n",
      "Epoch: 198\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8514\n",
      "Epoch: 199\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8344\n",
      "Epoch: 200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8409\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 201\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8537\n",
      "Epoch: 202\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8549\n",
      "Epoch: 203\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8447\n",
      "Epoch: 204\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8436\n",
      "Epoch: 205\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8464\n",
      "Epoch: 206\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8477\n",
      "Epoch: 207\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8336\n",
      "Epoch: 208\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8419\n",
      "Epoch: 209\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8499\n",
      "Epoch: 210\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8469\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 211\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8532\n",
      "Epoch: 212\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8461\n",
      "Epoch: 213\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8490\n",
      "Epoch: 214\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8372\n",
      "Epoch: 215\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8407\n",
      "Epoch: 216\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8418\n",
      "Epoch: 217\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8448\n",
      "Epoch: 218\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8394\n",
      "Epoch: 219\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8393\n",
      "Epoch: 220\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8307\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 12\n",
      "How many rows for non-start note at end: 0\n",
      "128 486\n",
      "Epoch: 221\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8410\n",
      "Epoch: 222\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8433\n",
      "Epoch: 223\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8444\n",
      "Epoch: 224\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8421\n",
      "Epoch: 225\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8206\n",
      "Epoch: 226\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8352\n",
      "Epoch: 227\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8311\n",
      "Epoch: 228\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8340\n",
      "Epoch: 229\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8427\n",
      "Epoch: 230\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8456\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 231\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8377\n",
      "Epoch: 232\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8346\n",
      "Epoch: 233\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8367\n",
      "Epoch: 234\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8400\n",
      "Epoch: 235\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8299\n",
      "Epoch: 236\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8407\n",
      "Epoch: 237\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8359\n",
      "Epoch: 238\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8308\n",
      "Epoch: 239\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8407\n",
      "Epoch: 240\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8305\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 241\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8382\n",
      "Epoch: 242\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8315\n",
      "Epoch: 243\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8473\n",
      "Epoch: 244\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8437\n",
      "Epoch: 245\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8422\n",
      "Epoch: 246\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8241\n",
      "Epoch: 247\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8345\n",
      "Epoch: 248\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.8291\n",
      "Epoch: 249\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8432\n",
      "Epoch: 250\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8221\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 251\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8226\n",
      "Epoch: 252\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8326\n",
      "Epoch: 253\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8353\n",
      "Epoch: 254\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8392\n",
      "Epoch: 255\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8391\n",
      "Epoch: 256\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8271\n",
      "Epoch: 257\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8256\n",
      "Epoch: 258\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8264\n",
      "Epoch: 259\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8211\n",
      "Epoch: 260\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8300\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 261\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8228\n",
      "Epoch: 262\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8276\n",
      "Epoch: 263\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8298\n",
      "Epoch: 264\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8294\n",
      "Epoch: 265\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8339\n",
      "Epoch: 266\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8232\n",
      "Epoch: 267\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8291\n",
      "Epoch: 268\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8121\n",
      "Epoch: 269\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8394\n",
      "Epoch: 270\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8278\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 4\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 271\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8275\n",
      "Epoch: 272\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8262\n",
      "Epoch: 273\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8254\n",
      "Epoch: 274\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8259\n",
      "Epoch: 275\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8214\n",
      "Epoch: 276\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8249\n",
      "Epoch: 277\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8267\n",
      "Epoch: 278\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8190\n",
      "Epoch: 279\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 2.8128\n",
      "Epoch: 280\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8244\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 281\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8244\n",
      "Epoch: 282\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8211\n",
      "Epoch: 283\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8186\n",
      "Epoch: 284\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8295\n",
      "Epoch: 285\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8294\n",
      "Epoch: 286\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8197\n",
      "Epoch: 287\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8241\n",
      "Epoch: 288\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8259\n",
      "Epoch: 289\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8135\n",
      "Epoch: 290\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8104\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 291\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8252\n",
      "Epoch: 292\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8233\n",
      "Epoch: 293\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8219\n",
      "Epoch: 294\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8196\n",
      "Epoch: 295\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8247\n",
      "Epoch: 296\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8147\n",
      "Epoch: 297\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8232\n",
      "Epoch: 298\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8182\n",
      "Epoch: 299\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8251\n",
      "Epoch: 300\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8228\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 301\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8165\n",
      "Epoch: 302\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8183\n",
      "Epoch: 303\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8303\n",
      "Epoch: 304\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8185\n",
      "Epoch: 305\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8117\n",
      "Epoch: 306\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8256\n",
      "Epoch: 307\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8193\n",
      "Epoch: 308\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8153\n",
      "Epoch: 309\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8181\n",
      "Epoch: 310\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8218\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 311\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8177\n",
      "Epoch: 312\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8159\n",
      "Epoch: 313\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8101\n",
      "Epoch: 314\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8116\n",
      "Epoch: 315\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8200\n",
      "Epoch: 316\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8201\n",
      "Epoch: 317\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8128\n",
      "Epoch: 318\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8125\n",
      "Epoch: 319\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8029\n",
      "Epoch: 320\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8201\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 321\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8213\n",
      "Epoch: 322\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8271\n",
      "Epoch: 323\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8074\n",
      "Epoch: 324\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8125\n",
      "Epoch: 325\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8142\n",
      "Epoch: 326\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8180\n",
      "Epoch: 327\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8153\n",
      "Epoch: 328\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8143\n",
      "Epoch: 329\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8197\n",
      "Epoch: 330\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8119\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 7\n",
      "How many rows for non-start note at end: 0\n",
      "128 491\n",
      "Epoch: 331\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8035\n",
      "Epoch: 332\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8077\n",
      "Epoch: 333\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8137\n",
      "Epoch: 334\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8088\n",
      "Epoch: 335\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8163\n",
      "Epoch: 336\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8099\n",
      "Epoch: 337\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8035\n",
      "Epoch: 338\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8161\n",
      "Epoch: 339\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8056\n",
      "Epoch: 340\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8152\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 341\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8076\n",
      "Epoch: 342\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8148\n",
      "Epoch: 343\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8100\n",
      "Epoch: 344\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8193\n",
      "Epoch: 345\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8098\n",
      "Epoch: 346\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8090\n",
      "Epoch: 347\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8080\n",
      "Epoch: 348\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8085\n",
      "Epoch: 349\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8016\n",
      "Epoch: 350\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8204\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 351\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8107\n",
      "Epoch: 352\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8079\n",
      "Epoch: 353\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7970\n",
      "Epoch: 354\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8044\n",
      "Epoch: 355\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.8138\n",
      "Epoch: 356\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.8082\n",
      "Epoch: 357\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8129\n",
      "Epoch: 358\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8047\n",
      "Epoch: 359\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8017\n",
      "Epoch: 360\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8021\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 361\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8039\n",
      "Epoch: 362\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8119\n",
      "Epoch: 363\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8020\n",
      "Epoch: 364\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8077\n",
      "Epoch: 365\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8034\n",
      "Epoch: 366\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8092\n",
      "Epoch: 367\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8118\n",
      "Epoch: 368\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8035\n",
      "Epoch: 369\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8108\n",
      "Epoch: 370\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8089\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 371\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.8088\n",
      "Epoch: 372\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8068\n",
      "Epoch: 373\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8059\n",
      "Epoch: 374\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8044\n",
      "Epoch: 375\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8165\n",
      "Epoch: 376\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8154\n",
      "Epoch: 377\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8047\n",
      "Epoch: 378\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8045\n",
      "Epoch: 379\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8016\n",
      "Epoch: 380\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7992\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 381\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8054\n",
      "Epoch: 382\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8026\n",
      "Epoch: 383\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8014\n",
      "Epoch: 384\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8086\n",
      "Epoch: 385\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8018\n",
      "Epoch: 386\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8085\n",
      "Epoch: 387\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7939\n",
      "Epoch: 388\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8160\n",
      "Epoch: 389\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8083\n",
      "Epoch: 390\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8166\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 4\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 391\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7951\n",
      "Epoch: 392\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8025\n",
      "Epoch: 393\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8117\n",
      "Epoch: 394\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7931\n",
      "Epoch: 395\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7981\n",
      "Epoch: 396\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8049\n",
      "Epoch: 397\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8010\n",
      "Epoch: 398\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7992\n",
      "Epoch: 399\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8012\n",
      "Epoch: 400\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8069\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 401\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7919\n",
      "Epoch: 402\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8047\n",
      "Epoch: 403\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8068\n",
      "Epoch: 404\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8050\n",
      "Epoch: 405\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7952\n",
      "Epoch: 406\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8034\n",
      "Epoch: 407\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8025\n",
      "Epoch: 408\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7985\n",
      "Epoch: 409\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8044\n",
      "Epoch: 410\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8144\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 411\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7960\n",
      "Epoch: 412\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7977\n",
      "Epoch: 413\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8054\n",
      "Epoch: 414\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8031\n",
      "Epoch: 415\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7906\n",
      "Epoch: 416\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7995\n",
      "Epoch: 417\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8018\n",
      "Epoch: 418\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.8053\n",
      "Epoch: 419\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7991\n",
      "Epoch: 420\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7954\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 421\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8012\n",
      "Epoch: 422\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7961\n",
      "Epoch: 423\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7925\n",
      "Epoch: 424\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8018\n",
      "Epoch: 425\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7908\n",
      "Epoch: 426\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7968\n",
      "Epoch: 427\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8052\n",
      "Epoch: 428\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.7983\n",
      "Epoch: 429\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7934\n",
      "Epoch: 430\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7977\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 431\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7988\n",
      "Epoch: 432\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7818\n",
      "Epoch: 433\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7958\n",
      "Epoch: 434\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7968\n",
      "Epoch: 435\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7976\n",
      "Epoch: 436\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7971\n",
      "Epoch: 437\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7957\n",
      "Epoch: 438\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7890\n",
      "Epoch: 439\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8025\n",
      "Epoch: 440\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7878\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 441\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8020\n",
      "Epoch: 442\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7971\n",
      "Epoch: 443\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7897\n",
      "Epoch: 444\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7933\n",
      "Epoch: 445\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7955\n",
      "Epoch: 446\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7860\n",
      "Epoch: 447\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8025\n",
      "Epoch: 448\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8043\n",
      "Epoch: 449\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7990\n",
      "Epoch: 450\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7945\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 451\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7933\n",
      "Epoch: 452\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7886\n",
      "Epoch: 453\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7977\n",
      "Epoch: 454\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7950\n",
      "Epoch: 455\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7962\n",
      "Epoch: 456\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7973\n",
      "Epoch: 457\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7839\n",
      "Epoch: 458\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7961\n",
      "Epoch: 459\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7976\n",
      "Epoch: 460\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7919\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 461\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7948\n",
      "Epoch: 462\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7926\n",
      "Epoch: 463\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7949\n",
      "Epoch: 464\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7790\n",
      "Epoch: 465\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7966\n",
      "Epoch: 466\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8045\n",
      "Epoch: 467\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7907\n",
      "Epoch: 468\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7921\n",
      "Epoch: 469\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7921\n",
      "Epoch: 470\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7984\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 4\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 471\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7884\n",
      "Epoch: 472\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7994\n",
      "Epoch: 473\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7990\n",
      "Epoch: 474\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7994\n",
      "Epoch: 475\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7882\n",
      "Epoch: 476\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7856\n",
      "Epoch: 477\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7789\n",
      "Epoch: 478\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7874\n",
      "Epoch: 479\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7876\n",
      "Epoch: 480\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7861\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 481\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.7909\n",
      "Epoch: 482\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7896\n",
      "Epoch: 483\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7888\n",
      "Epoch: 484\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7981\n",
      "Epoch: 485\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7942\n",
      "Epoch: 486\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7877\n",
      "Epoch: 487\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7920\n",
      "Epoch: 488\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7876\n",
      "Epoch: 489\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7900\n",
      "Epoch: 490\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7911\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 491\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7884\n",
      "Epoch: 492\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7797\n",
      "Epoch: 493\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7916\n",
      "Epoch: 494\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7832\n",
      "Epoch: 495\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7865\n",
      "Epoch: 496\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.8004\n",
      "Epoch: 497\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7867\n",
      "Epoch: 498\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7921\n",
      "Epoch: 499\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7871\n",
      "Epoch: 500\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7909\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 501\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7890\n",
      "Epoch: 502\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7908\n",
      "Epoch: 503\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7930\n",
      "Epoch: 504\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7888\n",
      "Epoch: 505\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7867\n",
      "Epoch: 506\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7893\n",
      "Epoch: 507\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7893\n",
      "Epoch: 508\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7730\n",
      "Epoch: 509\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7876\n",
      "Epoch: 510\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7878\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 511\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7870\n",
      "Epoch: 512\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7810\n",
      "Epoch: 513\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7875\n",
      "Epoch: 514\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7763\n",
      "Epoch: 515\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7942\n",
      "Epoch: 516\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7838\n",
      "Epoch: 517\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7839\n",
      "Epoch: 518\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7841\n",
      "Epoch: 519\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7836\n",
      "Epoch: 520\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7907\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 521\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7797\n",
      "Epoch: 522\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7935\n",
      "Epoch: 523\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7825\n",
      "Epoch: 524\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7772\n",
      "Epoch: 525\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7897\n",
      "Epoch: 526\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7811\n",
      "Epoch: 527\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7880\n",
      "Epoch: 528\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.7773\n",
      "Epoch: 529\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7762\n",
      "Epoch: 530\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7835\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 4\n",
      "How many rows for non-start note at end: 0\n",
      "128 494\n",
      "Epoch: 531\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7865\n",
      "Epoch: 532\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7776\n",
      "Epoch: 533\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7793\n",
      "Epoch: 534\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7971\n",
      "Epoch: 535\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7801\n",
      "Epoch: 536\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7840\n",
      "Epoch: 537\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7839\n",
      "Epoch: 538\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7805\n",
      "Epoch: 539\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7782\n",
      "Epoch: 540\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7765\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 6\n",
      "How many rows for non-start note at end: 0\n",
      "128 492\n",
      "Epoch: 541\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7873\n",
      "Epoch: 542\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7874\n",
      "Epoch: 543\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7792\n",
      "Epoch: 544\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7847\n",
      "Epoch: 545\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7786\n",
      "Epoch: 546\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7737\n",
      "Epoch: 547\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7771\n",
      "Epoch: 548\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7769\n",
      "Epoch: 549\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7762\n",
      "Epoch: 550\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7959\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 5\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 551\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7741\n",
      "Epoch: 552\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7706\n",
      "Epoch: 553\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7858\n",
      "Epoch: 554\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7833\n",
      "Epoch: 555\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7822\n",
      "Epoch: 556\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7841\n",
      "Epoch: 557\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7786\n",
      "Epoch: 558\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7795\n",
      "Epoch: 559\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7888\n",
      "Epoch: 560\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7808\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 5\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 561\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7891\n",
      "Epoch: 562\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7877\n",
      "Epoch: 563\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7823\n",
      "Epoch: 564\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7808\n",
      "Epoch: 565\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7973\n",
      "Epoch: 566\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7890\n",
      "Epoch: 567\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7836\n",
      "Epoch: 568\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7742\n",
      "Epoch: 569\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7821\n",
      "Epoch: 570\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7724\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 571\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7743\n",
      "Epoch: 572\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7833\n",
      "Epoch: 573\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7860\n",
      "Epoch: 574\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7658\n",
      "Epoch: 575\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 2.7747\n",
      "Epoch: 576\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7814\n",
      "Epoch: 577\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7710\n",
      "Epoch: 578\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7859\n",
      "Epoch: 579\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7929\n",
      "Epoch: 580\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7845\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 581\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7767\n",
      "Epoch: 582\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7820\n",
      "Epoch: 583\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7868\n",
      "Epoch: 584\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7801\n",
      "Epoch: 585\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7824\n",
      "Epoch: 586\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7874\n",
      "Epoch: 587\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7941\n",
      "Epoch: 588\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7818\n",
      "Epoch: 589\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7763\n",
      "Epoch: 590\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7762\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 591\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7735\n",
      "Epoch: 592\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7841\n",
      "Epoch: 593\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7790\n",
      "Epoch: 594\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7742\n",
      "Epoch: 595\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7713\n",
      "Epoch: 596\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7727\n",
      "Epoch: 597\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7832\n",
      "Epoch: 598\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7700\n",
      "Epoch: 599\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7580\n",
      "Epoch: 600\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7663\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 14\n",
      "How many rows for non-start note at end: 0\n",
      "128 484\n",
      "Epoch: 601\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7829\n",
      "Epoch: 602\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7814\n",
      "Epoch: 603\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7813\n",
      "Epoch: 604\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7670\n",
      "Epoch: 605\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7767\n",
      "Epoch: 606\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7842\n",
      "Epoch: 607\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7738\n",
      "Epoch: 608\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7710\n",
      "Epoch: 609\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7859\n",
      "Epoch: 610\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7805\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 611\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7802\n",
      "Epoch: 612\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7729\n",
      "Epoch: 613\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7695\n",
      "Epoch: 614\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7702\n",
      "Epoch: 615\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7773\n",
      "Epoch: 616\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7796\n",
      "Epoch: 617\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7770\n",
      "Epoch: 618\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7786\n",
      "Epoch: 619\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7800\n",
      "Epoch: 620\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7704\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 621\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7704\n",
      "Epoch: 622\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7742\n",
      "Epoch: 623\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7689\n",
      "Epoch: 624\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7764\n",
      "Epoch: 625\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7662\n",
      "Epoch: 626\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7683\n",
      "Epoch: 627\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7797\n",
      "Epoch: 628\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7657\n",
      "Epoch: 629\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7650\n",
      "Epoch: 630\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7656\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 631\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7781\n",
      "Epoch: 632\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7649\n",
      "Epoch: 633\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7768\n",
      "Epoch: 634\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7726\n",
      "Epoch: 635\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7699\n",
      "Epoch: 636\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7622\n",
      "Epoch: 637\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7725\n",
      "Epoch: 638\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7834\n",
      "Epoch: 639\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7628\n",
      "Epoch: 640\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7686\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 641\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7774\n",
      "Epoch: 642\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7735\n",
      "Epoch: 643\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7833\n",
      "Epoch: 644\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7745\n",
      "Epoch: 645\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7736\n",
      "Epoch: 646\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7724\n",
      "Epoch: 647\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7775\n",
      "Epoch: 648\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7722\n",
      "Epoch: 649\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7734\n",
      "Epoch: 650\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7782\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 651\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7806\n",
      "Epoch: 652\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7680\n",
      "Epoch: 653\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7869\n",
      "Epoch: 654\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7710\n",
      "Epoch: 655\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7701\n",
      "Epoch: 656\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7695\n",
      "Epoch: 657\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7706\n",
      "Epoch: 658\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7720\n",
      "Epoch: 659\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7616\n",
      "Epoch: 660\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7610\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 661\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7679\n",
      "Epoch: 662\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7712\n",
      "Epoch: 663\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7650\n",
      "Epoch: 664\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7698\n",
      "Epoch: 665\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7667\n",
      "Epoch: 666\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7688\n",
      "Epoch: 667\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7802\n",
      "Epoch: 668\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7814\n",
      "Epoch: 669\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7746\n",
      "Epoch: 670\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7640\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 671\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7694\n",
      "Epoch: 672\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7711\n",
      "Epoch: 673\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7738\n",
      "Epoch: 674\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7658\n",
      "Epoch: 675\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7681\n",
      "Epoch: 676\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7741\n",
      "Epoch: 677\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7761\n",
      "Epoch: 678\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7716\n",
      "Epoch: 679\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7737\n",
      "Epoch: 680\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7737\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 681\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7670\n",
      "Epoch: 682\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7716\n",
      "Epoch: 683\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7716\n",
      "Epoch: 684\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7709\n",
      "Epoch: 685\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7691\n",
      "Epoch: 686\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7583\n",
      "Epoch: 687\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7611\n",
      "Epoch: 688\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7736\n",
      "Epoch: 689\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7679\n",
      "Epoch: 690\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7669\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 691\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7738\n",
      "Epoch: 692\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7700\n",
      "Epoch: 693\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7722\n",
      "Epoch: 694\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7698\n",
      "Epoch: 695\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7672\n",
      "Epoch: 696\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7727\n",
      "Epoch: 697\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7755\n",
      "Epoch: 698\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7770\n",
      "Epoch: 699\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7680\n",
      "Epoch: 700\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7658\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 701\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7694\n",
      "Epoch: 702\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7557\n",
      "Epoch: 703\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7672\n",
      "Epoch: 704\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7642\n",
      "Epoch: 705\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7695\n",
      "Epoch: 706\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7689\n",
      "Epoch: 707\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7664\n",
      "Epoch: 708\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7762\n",
      "Epoch: 709\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7551\n",
      "Epoch: 710\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7726\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 711\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7703\n",
      "Epoch: 712\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7679\n",
      "Epoch: 713\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7653\n",
      "Epoch: 714\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7735\n",
      "Epoch: 715\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7783\n",
      "Epoch: 716\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7664\n",
      "Epoch: 717\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7660\n",
      "Epoch: 718\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7665\n",
      "Epoch: 719\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7629\n",
      "Epoch: 720\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7674\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 3\n",
      "How many rows for non-start note at end: 0\n",
      "128 495\n",
      "Epoch: 721\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7720\n",
      "Epoch: 722\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7697\n",
      "Epoch: 723\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7706\n",
      "Epoch: 724\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7674\n",
      "Epoch: 725\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7589\n",
      "Epoch: 726\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7633\n",
      "Epoch: 727\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7569\n",
      "Epoch: 728\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 2.7636\n",
      "Epoch: 729\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7579\n",
      "Epoch: 730\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7648\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 731\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7649\n",
      "Epoch: 732\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7628\n",
      "Epoch: 733\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7682\n",
      "Epoch: 734\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7736\n",
      "Epoch: 735\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7722\n",
      "Epoch: 736\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7654\n",
      "Epoch: 737\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7538\n",
      "Epoch: 738\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7706\n",
      "Epoch: 739\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7643\n",
      "Epoch: 740\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7701\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 2\n",
      "How many rows for non-start note at end: 0\n",
      "128 496\n",
      "Epoch: 741\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7700\n",
      "Epoch: 742\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7633\n",
      "Epoch: 743\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7623\n",
      "Epoch: 744\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7707\n",
      "Epoch: 745\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7645\n",
      "Epoch: 746\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7595\n",
      "Epoch: 747\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7566\n",
      "Epoch: 748\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7783\n",
      "Epoch: 749\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7741\n",
      "Epoch: 750\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7574\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 5\n",
      "How many rows for non-start note at end: 0\n",
      "128 493\n",
      "Epoch: 751\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7675\n",
      "Epoch: 752\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7661\n",
      "Epoch: 753\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7697\n",
      "Epoch: 754\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7592\n",
      "Epoch: 755\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7579\n",
      "Epoch: 756\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7603\n",
      "Epoch: 757\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7683\n",
      "Epoch: 758\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7727\n",
      "Epoch: 759\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7595\n",
      "Epoch: 760\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7664\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 761\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7671\n",
      "Epoch: 762\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7589\n",
      "Epoch: 763\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7643\n",
      "Epoch: 764\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7667\n",
      "Epoch: 765\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7624\n",
      "Epoch: 766\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7604\n",
      "Epoch: 767\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7589\n",
      "Epoch: 768\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7663\n",
      "Epoch: 769\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7692\n",
      "Epoch: 770\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7610\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n",
      "Epoch: 771\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7524\n",
      "Epoch: 772\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7644\n",
      "Epoch: 773\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7685\n",
      "Epoch: 774\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7604\n",
      "Epoch: 775\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7649\n",
      "Epoch: 776\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7515\n",
      "Epoch: 777\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7516\n",
      "Epoch: 778\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7561\n",
      "Epoch: 779\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7556\n",
      "Epoch: 780\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 2.7581\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 781\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7590\n",
      "Epoch: 782\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7650\n",
      "Epoch: 783\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7530\n",
      "Epoch: 784\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7564\n",
      "Epoch: 785\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7618\n",
      "Epoch: 786\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7553\n",
      "Epoch: 787\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7588\n",
      "Epoch: 788\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7613\n",
      "Epoch: 789\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7677\n",
      "Epoch: 790\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7613\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 498\n",
      "Epoch: 791\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.7690\n",
      "Epoch: 792\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7733\n",
      "Epoch: 793\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7527\n",
      "Epoch: 794\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7662\n",
      "Epoch: 795\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7668\n",
      "Epoch: 796\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7558\n",
      "Epoch: 797\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7726\n",
      "Epoch: 798\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7573\n",
      "Epoch: 799\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7538\n",
      "Epoch: 800\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.7491\n",
      "------ temperature: 1.2\n",
      "How many rows for non-start note at beginning: 1\n",
      "How many rows for non-start note at end: 0\n",
      "128 497\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "epoch_total = 801\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(1, epoch_total): # Train model with epoch_total \n",
    "    print('Epoch:', epoch)\n",
    "    model.fit(previous_full, predicted_full, batch_size=batch_size, epochs=1,\n",
    "              shuffle=True) # Fit model for 1 iteration.\n",
    "    \n",
    "\n",
    "    start_index = random.randint(0, len(midis_array)- max_len - 1)\n",
    "    \n",
    "    generated_midi = midis_array[start_index: start_index + max_len]\n",
    "        \n",
    "    if ((epoch%10) == 0):\n",
    "      model.save_weights('my_model_weights.h5')\n",
    "\n",
    "      for temperature in [1.2]:#1.2\n",
    "          print('------ temperature:', temperature)\n",
    "\n",
    "          for i in range(480):\n",
    "              samples = generated_midi[i:]\n",
    "              expanded_samples = np.expand_dims(samples, axis=0)\n",
    "              preds = model.predict(expanded_samples, verbose=0)[0]\n",
    "              preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "              next_array = sample(preds, temperature)\n",
    "              \n",
    "              midi_list = []\n",
    "              midi_list.append(generated_midi)\n",
    "              midi_list.append(next_array)\n",
    "              generated_midi = np.vstack(midi_list)\n",
    "              \n",
    "\n",
    "          generated_midi_final = np.transpose(generated_midi,(1,0))\n",
    "          output_notes = matrix_to_midi(generated_midi_final, random=1)\n",
    "          midi_stream = stream.Stream(output_notes)\n",
    "          midi_file_name = ('lstm_out_{}_{}.mid'.format(epoch, temperature))\n",
    "          midi_stream.write('midi', fp=midi_file_name)\n",
    "          parsed = converter.parse(midi_file_name)\n",
    "          for part in parsed.parts:\n",
    "              part.insert(0, instrument.Piano())\n",
    "          parsed.write('midi', fp=midi_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lstm weights: [array([[-0.04979481,  0.05581266,  0.12910399, ...,  0.08105253,\n",
      "        -0.04519383, -0.0983885 ],\n",
      "       [-0.06424947, -0.02610937,  0.00451878, ..., -0.05328028,\n",
      "        -0.01051417,  0.00781946],\n",
      "       [-0.03881602, -0.01100801, -0.0893052 , ..., -0.09520359,\n",
      "        -0.07624336, -0.05740413],\n",
      "       ...,\n",
      "       [ 0.13599263,  0.11619855, -0.07559689, ...,  0.0748588 ,\n",
      "        -0.0112953 ,  0.15732554],\n",
      "       [-0.05864222, -0.05930268, -0.11011054, ..., -0.04076448,\n",
      "         0.13113849,  0.06749234],\n",
      "       [ 0.02729206, -0.05549179,  0.12862282, ...,  0.07921708,\n",
      "         0.01449012, -0.09380601]], dtype=float32), array([-0.01964077, -0.01979916, -0.01988151, -0.01965138, -0.01972788,\n",
      "       -0.01971992, -0.01966167, -0.01973956, -0.01981277, -0.01963289,\n",
      "       -0.0197427 , -0.01972683, -0.01971684, -0.01971309, -0.01969555,\n",
      "       -0.01975541, -0.01944502, -0.01947654, -0.01953768, -0.01977709,\n",
      "       -0.01968654, -0.01973486, -0.01981986, -0.01978236, -0.01961032,\n",
      "       -0.01968229, -0.01977448, -0.01981691, -0.01978024, -0.01970347,\n",
      "       -0.01986096, -0.01965762, -0.01972097, -0.0197535 , -0.0196018 ,\n",
      "       -0.01944755, -0.01946448, -0.01972765, -0.01689906, -0.01982159,\n",
      "       -0.01712018, -0.01229786, -0.01973412,  0.00371616, -0.01978377,\n",
      "        0.00416861, -0.01982379,  0.0088727 ,  0.01570287, -0.01955836,\n",
      "        0.01611106, -0.01960848,  0.01683046,  0.01708989, -0.01958557,\n",
      "        0.01768588, -0.01979394,  0.01524465, -0.01973788,  0.01662027,\n",
      "        0.01680568, -0.01967327,  0.01603113, -0.01972283,  0.01671816,\n",
      "        0.01725454, -0.01983244,  0.0180381 , -0.01981914,  0.01772375,\n",
      "       -0.01972003,  0.01707541,  0.01674027, -0.01989024,  0.01427346,\n",
      "       -0.01974309,  0.01331309, -0.00015905, -0.01975755, -0.01567897,\n",
      "       -0.01959582, -0.01962752, -0.01966399, -0.01908015, -0.01982656,\n",
      "       -0.01969644, -0.01959637, -0.01957099, -0.01880219, -0.0197171 ,\n",
      "       -0.01946627, -0.01974232, -0.01969875, -0.01976677, -0.01968734,\n",
      "       -0.01976546, -0.01974167, -0.01963761, -0.01969524, -0.01967436,\n",
      "       -0.01972912, -0.01997018, -0.019771  , -0.01967283, -0.01970053,\n",
      "       -0.01971266, -0.0194828 , -0.01982414, -0.01969474, -0.01978747,\n",
      "       -0.01988969, -0.01967354, -0.01965231, -0.01961731, -0.01973562,\n",
      "       -0.01944129, -0.01961818, -0.01965918, -0.01970917, -0.01975932,\n",
      "       -0.01969473, -0.01974749, -0.01975178, -0.01970242, -0.0197841 ,\n",
      "       -0.01966101, -0.01958321, -0.01967017], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    lstm_weights = layer.get_weights() # list of numpy arrays\n",
    "\n",
    "print ('Lstm weights:', lstm_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "start_index = random.randint(0, len(midis_array)- max_len - 1)\n",
    "    \n",
    "generated_midi = midis_array[start_index: start_index + max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ temperature: 0.7\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 698\n",
      "------ temperature: 2.7\n",
      "How many rows for non-start note at beginning: 0\n",
      "How many rows for non-start note at end: 0\n",
      "128 698\n"
     ]
    }
   ],
   "source": [
    "for temperature in [0.7, 2.7]:\n",
    "        print('------ temperature:', temperature)\n",
    "        generated_midi = midis_array[start_index: start_index + max_len]\n",
    "        for i in range(680):\n",
    "            samples = generated_midi[i:]\n",
    "            expanded_samples = np.expand_dims(samples, axis=0)\n",
    "            preds = model.predict(expanded_samples, verbose=0)[0]\n",
    "            preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "            next_array = sample(preds, temperature)\n",
    "           \n",
    "            midi_list = []\n",
    "            midi_list.append(generated_midi)\n",
    "            midi_list.append(next_array)\n",
    "            generated_midi = np.vstack(midi_list)\n",
    "            \n",
    "\n",
    "        generated_midi_final = np.transpose(generated_midi,(1,0))\n",
    "        output_notes = matrix_to_midi(generated_midi_final, random=1)\n",
    "        midi_stream = stream.Stream(output_notes)\n",
    "        midi_file_name = ('lstm_out_{}.mid'.format(temperature))\n",
    "        midi_stream.write('midi', fp=midi_file_name)\n",
    "        parsed = converter.parse(midi_file_name)\n",
    "        for part in parsed.parts:\n",
    "            part.insert(0, instrument.Piano())\n",
    "        parsed.write('midi', fp=midi_file_name)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02346924 0.01647065 0.01544844 0.01553862 0.01555491 0.02911818\n",
      " 0.01562885 0.02612231 0.0247381  0.01616732 0.0155949  0.08395524\n",
      " 0.02296312 0.02422718 0.02813246 0.01558293 0.02189464 0.02258543\n",
      " 0.02252005 0.01841837]\n",
      "max: 0.08395523577928543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zed/.conda/envs/music_base/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "import bottleneck \n",
    "z = -bottleneck.partition(-preds, 20)[:20]\n",
    "print (z)\n",
    "print ('max:', np.max(preds))\n",
    "\n",
    "model.save('my_model.h5')\n",
    "\n",
    "model.save_weights('my_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f14c9d35ad22571b3213e3ba997bc600b8e5211eed475dc9e01b97aa57593897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
